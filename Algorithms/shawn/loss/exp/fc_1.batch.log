epoch 0/200,training loss:0.688380,validation loss:0.686855
epoch 1/200,training loss:0.685087,validation loss:0.683314
epoch 2/200,training loss:0.681087,validation loss:0.678735
epoch 3/200,training loss:0.675773,validation loss:0.672603
epoch 4/200,training loss:0.668883,validation loss:0.664990
epoch 5/200,training loss:0.660924,validation loss:0.656861
epoch 6/200,training loss:0.653109,validation loss:0.649609
epoch 7/200,training loss:0.646673,validation loss:0.644067
epoch 8/200,training loss:0.641965,validation loss:0.640194
epoch 9/200,training loss:0.638751,validation loss:0.637553
epoch 10/200,training loss:0.636536,validation loss:0.635737
epoch 11/200,training loss:0.634961,validation loss:0.634436
epoch 12/200,training loss:0.633846,validation loss:0.633488
epoch 13/200,training loss:0.633037,validation loss:0.632780
epoch 14/200,training loss:0.632406,validation loss:0.632248
epoch 15/200,training loss:0.631984,validation loss:0.631841
epoch 16/200,training loss:0.631577,validation loss:0.631528
epoch 17/200,training loss:0.631297,validation loss:0.631281
epoch 18/200,training loss:0.631074,validation loss:0.631097
epoch 19/200,training loss:0.630921,validation loss:0.630938
epoch 20/200,training loss:0.630742,validation loss:0.630814
epoch 21/200,training loss:0.630626,validation loss:0.630714
epoch 22/200,training loss:0.630593,validation loss:0.630630
epoch 23/200,training loss:0.630480,validation loss:0.630565
epoch 24/200,training loss:0.630397,validation loss:0.630501
epoch 25/200,training loss:0.630330,validation loss:0.630447
epoch 26/200,training loss:0.630278,validation loss:0.630402
epoch 27/200,training loss:0.630258,validation loss:0.630363
epoch 28/200,training loss:0.630186,validation loss:0.630326
epoch 29/200,training loss:0.630157,validation loss:0.630305
epoch 30/200,training loss:0.630110,validation loss:0.630270
epoch 31/200,training loss:0.630099,validation loss:0.630246
epoch 32/200,training loss:0.630054,validation loss:0.630220
epoch 33/200,training loss:0.630046,validation loss:0.630196
epoch 34/200,training loss:0.629993,validation loss:0.630173
epoch 35/200,training loss:0.629977,validation loss:0.630151
epoch 36/200,training loss:0.629970,validation loss:0.630130
epoch 37/200,training loss:0.629951,validation loss:0.630114
epoch 38/200,training loss:0.629912,validation loss:0.630095
epoch 39/200,training loss:0.629900,validation loss:0.630083
epoch 40/200,training loss:0.629877,validation loss:0.630065
epoch 41/200,training loss:0.629842,validation loss:0.630037
epoch 42/200,training loss:0.629848,validation loss:0.630028
epoch 43/200,training loss:0.629791,validation loss:0.630010
epoch 44/200,training loss:0.629725,validation loss:0.629987
epoch 45/200,training loss:0.629750,validation loss:0.629969
epoch 46/200,training loss:0.629705,validation loss:0.629962
epoch 47/200,training loss:0.629718,validation loss:0.629935
epoch 48/200,training loss:0.629689,validation loss:0.629927
epoch 49/200,training loss:0.629621,validation loss:0.629900
epoch 50/200,training loss:0.629651,validation loss:0.629882
epoch 51/200,training loss:0.629581,validation loss:0.629864
epoch 52/200,training loss:0.629597,validation loss:0.629848
epoch 53/200,training loss:0.629572,validation loss:0.629831
epoch 54/200,training loss:0.629551,validation loss:0.629819
epoch 55/200,training loss:0.629525,validation loss:0.629789
epoch 56/200,training loss:0.629493,validation loss:0.629770
epoch 57/200,training loss:0.629445,validation loss:0.629759
epoch 58/200,training loss:0.629469,validation loss:0.629738
epoch 59/200,training loss:0.629436,validation loss:0.629716
epoch 60/200,training loss:0.629348,validation loss:0.629690
epoch 61/200,training loss:0.629366,validation loss:0.629671
epoch 62/200,training loss:0.629325,validation loss:0.629645
epoch 63/200,training loss:0.629261,validation loss:0.629626
epoch 64/200,training loss:0.629276,validation loss:0.629603
epoch 65/200,training loss:0.629237,validation loss:0.629579
epoch 66/200,training loss:0.629231,validation loss:0.629561
epoch 67/200,training loss:0.629191,validation loss:0.629532
epoch 68/200,training loss:0.629154,validation loss:0.629504
epoch 69/200,training loss:0.629138,validation loss:0.629484
epoch 70/200,training loss:0.629081,validation loss:0.629456
epoch 71/200,training loss:0.629052,validation loss:0.629428
epoch 72/200,training loss:0.628985,validation loss:0.629407
epoch 73/200,training loss:0.628996,validation loss:0.629385
epoch 74/200,training loss:0.628954,validation loss:0.629365
epoch 75/200,training loss:0.628892,validation loss:0.629318
epoch 76/200,training loss:0.628932,validation loss:0.629296
epoch 77/200,training loss:0.628845,validation loss:0.629263
epoch 78/200,training loss:0.628794,validation loss:0.629235
epoch 79/200,training loss:0.628777,validation loss:0.629200
epoch 80/200,training loss:0.628710,validation loss:0.629173
epoch 81/200,training loss:0.628728,validation loss:0.629141
epoch 82/200,training loss:0.628676,validation loss:0.629112
epoch 83/200,training loss:0.628606,validation loss:0.629077
epoch 84/200,training loss:0.628563,validation loss:0.629043
epoch 85/200,training loss:0.628519,validation loss:0.629023
epoch 86/200,training loss:0.628505,validation loss:0.628981
epoch 87/200,training loss:0.628445,validation loss:0.628944
epoch 88/200,training loss:0.628426,validation loss:0.628908
epoch 89/200,training loss:0.628358,validation loss:0.628871
epoch 90/200,training loss:0.628287,validation loss:0.628839
epoch 91/200,training loss:0.628294,validation loss:0.628804
epoch 92/200,training loss:0.628233,validation loss:0.628765
epoch 93/200,training loss:0.628195,validation loss:0.628725
epoch 94/200,training loss:0.628172,validation loss:0.628686
epoch 95/200,training loss:0.628100,validation loss:0.628642
epoch 96/200,training loss:0.628030,validation loss:0.628604
epoch 97/200,training loss:0.627997,validation loss:0.628573
epoch 98/200,training loss:0.627964,validation loss:0.628525
epoch 99/200,training loss:0.627917,validation loss:0.628485
epoch 100/200,training loss:0.627828,validation loss:0.628440
epoch 101/200,training loss:0.627802,validation loss:0.628397
epoch 102/200,training loss:0.627753,validation loss:0.628360
epoch 103/200,training loss:0.627724,validation loss:0.628314
epoch 104/200,training loss:0.627623,validation loss:0.628266
epoch 105/200,training loss:0.627605,validation loss:0.628224
epoch 106/200,training loss:0.627546,validation loss:0.628189
epoch 107/200,training loss:0.627458,validation loss:0.628137
epoch 108/200,training loss:0.627424,validation loss:0.628089
epoch 109/200,training loss:0.627385,validation loss:0.628040
epoch 110/200,training loss:0.627337,validation loss:0.627997
epoch 111/200,training loss:0.627306,validation loss:0.627957
epoch 112/200,training loss:0.627219,validation loss:0.627902
epoch 113/200,training loss:0.627154,validation loss:0.627852
epoch 114/200,training loss:0.627097,validation loss:0.627802
epoch 115/200,training loss:0.627014,validation loss:0.627760
epoch 116/200,training loss:0.626991,validation loss:0.627705
epoch 117/200,training loss:0.626920,validation loss:0.627658
epoch 118/200,training loss:0.626860,validation loss:0.627600
epoch 119/200,training loss:0.626793,validation loss:0.627552
epoch 120/200,training loss:0.626760,validation loss:0.627501
epoch 121/200,training loss:0.626671,validation loss:0.627448
epoch 122/200,training loss:0.626590,validation loss:0.627395
epoch 123/200,training loss:0.626525,validation loss:0.627347
epoch 124/200,training loss:0.626499,validation loss:0.627288
epoch 125/200,training loss:0.626440,validation loss:0.627248
epoch 126/200,training loss:0.626334,validation loss:0.627192
epoch 127/200,training loss:0.626309,validation loss:0.627128
epoch 128/200,training loss:0.626212,validation loss:0.627076
epoch 129/200,training loss:0.626136,validation loss:0.627021
epoch 130/200,training loss:0.626083,validation loss:0.626976
epoch 131/200,training loss:0.626035,validation loss:0.626913
epoch 132/200,training loss:0.625939,validation loss:0.626856
epoch 133/200,training loss:0.625879,validation loss:0.626803
epoch 134/200,training loss:0.625812,validation loss:0.626747
epoch 135/200,training loss:0.625751,validation loss:0.626693
epoch 136/200,training loss:0.625686,validation loss:0.626635
epoch 137/200,training loss:0.625601,validation loss:0.626583
epoch 138/200,training loss:0.625595,validation loss:0.626520
epoch 139/200,training loss:0.625484,validation loss:0.626463
epoch 140/200,training loss:0.625443,validation loss:0.626407
epoch 141/200,training loss:0.625375,validation loss:0.626349
epoch 142/200,training loss:0.625245,validation loss:0.626295
epoch 143/200,training loss:0.625221,validation loss:0.626238
epoch 144/200,training loss:0.625164,validation loss:0.626185
epoch 145/200,training loss:0.625053,validation loss:0.626120
epoch 146/200,training loss:0.625010,validation loss:0.626066
epoch 147/200,training loss:0.624904,validation loss:0.626006
epoch 148/200,training loss:0.624851,validation loss:0.625948
epoch 149/200,training loss:0.624774,validation loss:0.625886
epoch 150/200,training loss:0.624710,validation loss:0.625845
epoch 151/200,training loss:0.624629,validation loss:0.625780
epoch 152/200,training loss:0.624565,validation loss:0.625714
epoch 153/200,training loss:0.624484,validation loss:0.625660
epoch 154/200,training loss:0.624389,validation loss:0.625598
epoch 155/200,training loss:0.624336,validation loss:0.625539
epoch 156/200,training loss:0.624282,validation loss:0.625482
epoch 157/200,training loss:0.624212,validation loss:0.625446
epoch 158/200,training loss:0.624121,validation loss:0.625364
epoch 159/200,training loss:0.624052,validation loss:0.625305
epoch 160/200,training loss:0.623957,validation loss:0.625248
epoch 161/200,training loss:0.623910,validation loss:0.625187
epoch 162/200,training loss:0.623824,validation loss:0.625142
epoch 163/200,training loss:0.623758,validation loss:0.625073
epoch 164/200,training loss:0.623680,validation loss:0.625010
epoch 165/200,training loss:0.623614,validation loss:0.624953
epoch 166/200,training loss:0.623558,validation loss:0.624895
epoch 167/200,training loss:0.623479,validation loss:0.624840
epoch 168/200,training loss:0.623394,validation loss:0.624781
epoch 169/200,training loss:0.623313,validation loss:0.624723
epoch 170/200,training loss:0.623248,validation loss:0.624671
epoch 171/200,training loss:0.623176,validation loss:0.624604
epoch 172/200,training loss:0.623141,validation loss:0.624547
epoch 173/200,training loss:0.623050,validation loss:0.624491
epoch 174/200,training loss:0.622968,validation loss:0.624439
epoch 175/200,training loss:0.622909,validation loss:0.624377
epoch 176/200,training loss:0.622804,validation loss:0.624320
epoch 177/200,training loss:0.622752,validation loss:0.624263
epoch 178/200,training loss:0.622668,validation loss:0.624209
epoch 179/200,training loss:0.622584,validation loss:0.624150
epoch 180/200,training loss:0.622543,validation loss:0.624094
epoch 181/200,training loss:0.622458,validation loss:0.624035
epoch 182/200,training loss:0.622395,validation loss:0.623984
epoch 183/200,training loss:0.622317,validation loss:0.623921
epoch 184/200,training loss:0.622185,validation loss:0.623868
epoch 185/200,training loss:0.622167,validation loss:0.623816
epoch 186/200,training loss:0.622081,validation loss:0.623763
epoch 187/200,training loss:0.621998,validation loss:0.623719
epoch 188/200,training loss:0.621965,validation loss:0.623651
epoch 189/200,training loss:0.621843,validation loss:0.623591
epoch 190/200,training loss:0.621810,validation loss:0.623534
epoch 191/200,training loss:0.621720,validation loss:0.623481
epoch 192/200,training loss:0.621668,validation loss:0.623434
epoch 193/200,training loss:0.621606,validation loss:0.623379
epoch 194/200,training loss:0.621547,validation loss:0.623327
epoch 195/200,training loss:0.621446,validation loss:0.623269
epoch 196/200,training loss:0.621377,validation loss:0.623214
epoch 197/200,training loss:0.621330,validation loss:0.623171
epoch 198/200,training loss:0.621242,validation loss:0.623129
epoch 199/200,training loss:0.621172,validation loss:0.623057
Finished. Saving the model to /h/172/shawnlyu/projects/machine_learning/CSC2515Dota2DraftPredictionProject/algorithms/shawn/exp/fc_1.batch.pth
The best validation accuracy occurs at 0th epoch