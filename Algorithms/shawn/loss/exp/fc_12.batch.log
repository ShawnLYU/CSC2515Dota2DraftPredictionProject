epoch 0/800,training loss:0.690513,validation loss:0.690307
epoch 1/800,training loss:0.690161,validation loss:0.690245
epoch 2/800,training loss:0.690025,validation loss:0.690073
epoch 3/800,training loss:0.689964,validation loss:0.690044
epoch 4/800,training loss:0.689916,validation loss:0.689918
epoch 5/800,training loss:0.689772,validation loss:0.689898
epoch 6/800,training loss:0.689688,validation loss:0.689790
epoch 7/800,training loss:0.689674,validation loss:0.689677
epoch 8/800,training loss:0.689490,validation loss:0.689545
epoch 9/800,training loss:0.689422,validation loss:0.689487
epoch 10/800,training loss:0.689276,validation loss:0.689266
epoch 11/800,training loss:0.689105,validation loss:0.689225
epoch 12/800,training loss:0.688947,validation loss:0.688946
epoch 13/800,training loss:0.688749,validation loss:0.688715
epoch 14/800,training loss:0.688431,validation loss:0.688316
epoch 15/800,training loss:0.688091,validation loss:0.687988
epoch 16/800,training loss:0.687610,validation loss:0.687478
epoch 17/800,training loss:0.687062,validation loss:0.686720
epoch 18/800,training loss:0.686128,validation loss:0.685676
epoch 19/800,training loss:0.685012,validation loss:0.684375
epoch 20/800,training loss:0.683372,validation loss:0.682486
epoch 21/800,training loss:0.681131,validation loss:0.679911
epoch 22/800,training loss:0.678474,validation loss:0.676772
epoch 23/800,training loss:0.674926,validation loss:0.673239
epoch 24/800,training loss:0.671224,validation loss:0.669061
epoch 25/800,training loss:0.667574,validation loss:0.665702
epoch 26/800,training loss:0.664303,validation loss:0.662778
epoch 27/800,training loss:0.661299,validation loss:0.660117
epoch 28/800,training loss:0.658927,validation loss:0.657930
epoch 29/800,training loss:0.657066,validation loss:0.655671
epoch 30/800,training loss:0.655207,validation loss:0.654284
epoch 31/800,training loss:0.653533,validation loss:0.652992
epoch 32/800,training loss:0.652583,validation loss:0.651846
epoch 33/800,training loss:0.651291,validation loss:0.650845
epoch 34/800,training loss:0.650363,validation loss:0.649662
epoch 35/800,training loss:0.649304,validation loss:0.649167
epoch 36/800,training loss:0.648397,validation loss:0.648471
epoch 37/800,training loss:0.647693,validation loss:0.647795
epoch 38/800,training loss:0.647410,validation loss:0.647126
epoch 39/800,training loss:0.646418,validation loss:0.646650
epoch 40/800,training loss:0.646148,validation loss:0.645881
epoch 41/800,training loss:0.645550,validation loss:0.645654
epoch 42/800,training loss:0.645067,validation loss:0.644938
epoch 43/800,training loss:0.644553,validation loss:0.644658
epoch 44/800,training loss:0.644209,validation loss:0.644175
epoch 45/800,training loss:0.643775,validation loss:0.643679
epoch 46/800,training loss:0.643752,validation loss:0.643635
epoch 47/800,training loss:0.643061,validation loss:0.643527
epoch 48/800,training loss:0.642849,validation loss:0.642772
epoch 49/800,training loss:0.642723,validation loss:0.642514
epoch 50/800,training loss:0.642190,validation loss:0.642244
epoch 51/800,training loss:0.642143,validation loss:0.642488
epoch 52/800,training loss:0.641871,validation loss:0.641925
epoch 53/800,training loss:0.641677,validation loss:0.641969
epoch 54/800,training loss:0.641265,validation loss:0.641742
epoch 55/800,training loss:0.641337,validation loss:0.641374
epoch 56/800,training loss:0.641011,validation loss:0.641238
epoch 57/800,training loss:0.640710,validation loss:0.640569
epoch 58/800,training loss:0.640570,validation loss:0.640821
epoch 59/800,training loss:0.640541,validation loss:0.640200
epoch 60/800,training loss:0.640290,validation loss:0.640748
epoch 61/800,training loss:0.639965,validation loss:0.640139
epoch 62/800,training loss:0.640101,validation loss:0.640218
epoch 63/800,training loss:0.639887,validation loss:0.639851
epoch 64/800,training loss:0.639667,validation loss:0.639930
epoch 65/800,training loss:0.639331,validation loss:0.639588
epoch 66/800,training loss:0.639363,validation loss:0.639603
epoch 67/800,training loss:0.639353,validation loss:0.639203
epoch 68/800,training loss:0.639186,validation loss:0.639117
epoch 69/800,training loss:0.639060,validation loss:0.639320
epoch 70/800,training loss:0.638718,validation loss:0.639334
epoch 71/800,training loss:0.638637,validation loss:0.639096
epoch 72/800,training loss:0.638498,validation loss:0.638955
epoch 73/800,training loss:0.638615,validation loss:0.638822
epoch 74/800,training loss:0.638367,validation loss:0.638657
epoch 75/800,training loss:0.638399,validation loss:0.638472
epoch 76/800,training loss:0.638310,validation loss:0.638368
epoch 77/800,training loss:0.637924,validation loss:0.638148
epoch 78/800,training loss:0.637833,validation loss:0.638659
epoch 79/800,training loss:0.637919,validation loss:0.638198
epoch 80/800,training loss:0.637643,validation loss:0.638208
epoch 81/800,training loss:0.637492,validation loss:0.637843
epoch 82/800,training loss:0.637558,validation loss:0.637642
epoch 83/800,training loss:0.637274,validation loss:0.637874
epoch 84/800,training loss:0.637223,validation loss:0.638004
epoch 85/800,training loss:0.637120,validation loss:0.637441
epoch 86/800,training loss:0.637136,validation loss:0.637679
epoch 87/800,training loss:0.637014,validation loss:0.637659
epoch 88/800,training loss:0.636961,validation loss:0.637703
epoch 89/800,training loss:0.637016,validation loss:0.637348
epoch 90/800,training loss:0.637028,validation loss:0.637376
epoch 91/800,training loss:0.636900,validation loss:0.636984
epoch 92/800,training loss:0.636422,validation loss:0.637130
epoch 93/800,training loss:0.636709,validation loss:0.637276
epoch 94/800,training loss:0.636605,validation loss:0.637068
epoch 95/800,training loss:0.636665,validation loss:0.637082
epoch 96/800,training loss:0.636435,validation loss:0.637075
epoch 97/800,training loss:0.636466,validation loss:0.637060
epoch 98/800,training loss:0.636299,validation loss:0.636781
epoch 99/800,training loss:0.636261,validation loss:0.636877
epoch 100/800,training loss:0.636285,validation loss:0.636687
epoch 101/800,training loss:0.636141,validation loss:0.636563
epoch 102/800,training loss:0.636246,validation loss:0.636559
epoch 103/800,training loss:0.636086,validation loss:0.636471
epoch 104/800,training loss:0.636009,validation loss:0.636223
epoch 105/800,training loss:0.635819,validation loss:0.636093
epoch 106/800,training loss:0.635770,validation loss:0.636495
epoch 107/800,training loss:0.635992,validation loss:0.636402
epoch 108/800,training loss:0.635718,validation loss:0.636184
epoch 109/800,training loss:0.635729,validation loss:0.636314
epoch 110/800,training loss:0.635489,validation loss:0.636224
epoch 111/800,training loss:0.635435,validation loss:0.636298
epoch 112/800,training loss:0.635398,validation loss:0.636107
epoch 113/800,training loss:0.635245,validation loss:0.635892
epoch 114/800,training loss:0.635378,validation loss:0.635741
epoch 115/800,training loss:0.635192,validation loss:0.636044
epoch 116/800,training loss:0.635285,validation loss:0.635848
epoch 117/800,training loss:0.635202,validation loss:0.635436
epoch 118/800,training loss:0.634937,validation loss:0.635488
epoch 119/800,training loss:0.635237,validation loss:0.635439
epoch 120/800,training loss:0.635033,validation loss:0.635948
epoch 121/800,training loss:0.634984,validation loss:0.635465
epoch 122/800,training loss:0.635102,validation loss:0.635161
epoch 123/800,training loss:0.634844,validation loss:0.635596
epoch 124/800,training loss:0.634659,validation loss:0.635307
epoch 125/800,training loss:0.634932,validation loss:0.635281
epoch 126/800,training loss:0.634702,validation loss:0.635301
epoch 127/800,training loss:0.634762,validation loss:0.635461
epoch 128/800,training loss:0.634605,validation loss:0.635220
epoch 129/800,training loss:0.634631,validation loss:0.635344
epoch 130/800,training loss:0.634725,validation loss:0.635335
epoch 131/800,training loss:0.634495,validation loss:0.635155
epoch 132/800,training loss:0.634363,validation loss:0.635003
epoch 133/800,training loss:0.634276,validation loss:0.634865
epoch 134/800,training loss:0.634247,validation loss:0.635052
epoch 135/800,training loss:0.634237,validation loss:0.634952
epoch 136/800,training loss:0.634166,validation loss:0.634914
epoch 137/800,training loss:0.634081,validation loss:0.634878
epoch 138/800,training loss:0.633839,validation loss:0.634842
epoch 139/800,training loss:0.634049,validation loss:0.634950
epoch 140/800,training loss:0.633989,validation loss:0.634658
epoch 141/800,training loss:0.634075,validation loss:0.634385
epoch 142/800,training loss:0.634053,validation loss:0.634693
epoch 143/800,training loss:0.633747,validation loss:0.634496
epoch 144/800,training loss:0.633764,validation loss:0.634599
epoch 145/800,training loss:0.633825,validation loss:0.634537
epoch 146/800,training loss:0.633596,validation loss:0.634548
epoch 147/800,training loss:0.633615,validation loss:0.634062
epoch 148/800,training loss:0.633480,validation loss:0.634694
epoch 149/800,training loss:0.633642,validation loss:0.634486
epoch 150/800,training loss:0.633595,validation loss:0.634463
epoch 151/800,training loss:0.633569,validation loss:0.634242
epoch 152/800,training loss:0.633517,validation loss:0.634121
epoch 153/800,training loss:0.633384,validation loss:0.634233
epoch 154/800,training loss:0.633368,validation loss:0.634194
epoch 155/800,training loss:0.633257,validation loss:0.634268
epoch 156/800,training loss:0.633113,validation loss:0.634146
epoch 157/800,training loss:0.633235,validation loss:0.634031
epoch 158/800,training loss:0.633023,validation loss:0.633924
epoch 159/800,training loss:0.633280,validation loss:0.633790
epoch 160/800,training loss:0.633076,validation loss:0.633941
epoch 161/800,training loss:0.632951,validation loss:0.633936
epoch 162/800,training loss:0.633121,validation loss:0.633681
epoch 163/800,training loss:0.632955,validation loss:0.634053
epoch 164/800,training loss:0.632852,validation loss:0.633598
epoch 165/800,training loss:0.632706,validation loss:0.633508
epoch 166/800,training loss:0.632621,validation loss:0.633863
epoch 167/800,training loss:0.632641,validation loss:0.633580
epoch 168/800,training loss:0.632701,validation loss:0.633513
epoch 169/800,training loss:0.632645,validation loss:0.633599
epoch 170/800,training loss:0.632432,validation loss:0.633747
epoch 171/800,training loss:0.632457,validation loss:0.633749
epoch 172/800,training loss:0.632349,validation loss:0.633287
epoch 173/800,training loss:0.632364,validation loss:0.633291
epoch 174/800,training loss:0.632390,validation loss:0.633426
epoch 175/800,training loss:0.632395,validation loss:0.633464
epoch 176/800,training loss:0.632145,validation loss:0.633401
epoch 177/800,training loss:0.631993,validation loss:0.633003
epoch 178/800,training loss:0.631877,validation loss:0.633107
epoch 179/800,training loss:0.632064,validation loss:0.633146
epoch 180/800,training loss:0.631933,validation loss:0.632942
epoch 181/800,training loss:0.632075,validation loss:0.633108
epoch 182/800,training loss:0.631795,validation loss:0.633120
epoch 183/800,training loss:0.632045,validation loss:0.632861
epoch 184/800,training loss:0.631784,validation loss:0.632756
epoch 185/800,training loss:0.631874,validation loss:0.632808
epoch 186/800,training loss:0.631676,validation loss:0.633206
epoch 187/800,training loss:0.631605,validation loss:0.632800
epoch 188/800,training loss:0.631675,validation loss:0.632872
epoch 189/800,training loss:0.631754,validation loss:0.632843
epoch 190/800,training loss:0.631577,validation loss:0.632751
epoch 191/800,training loss:0.631395,validation loss:0.632765
epoch 192/800,training loss:0.631507,validation loss:0.632698
epoch 193/800,training loss:0.631380,validation loss:0.632702
epoch 194/800,training loss:0.631318,validation loss:0.632561
epoch 195/800,training loss:0.631302,validation loss:0.632476
epoch 196/800,training loss:0.631352,validation loss:0.632574
epoch 197/800,training loss:0.631293,validation loss:0.632430
epoch 198/800,training loss:0.631137,validation loss:0.632521
epoch 199/800,training loss:0.631113,validation loss:0.632105
epoch 200/800,training loss:0.631136,validation loss:0.632166
epoch 201/800,training loss:0.631096,validation loss:0.632408
epoch 202/800,training loss:0.630993,validation loss:0.632226
epoch 203/800,training loss:0.630829,validation loss:0.632387
epoch 204/800,training loss:0.631114,validation loss:0.632349
epoch 205/800,training loss:0.630847,validation loss:0.632003
epoch 206/800,training loss:0.630692,validation loss:0.632106
epoch 207/800,training loss:0.630900,validation loss:0.632068
epoch 208/800,training loss:0.630702,validation loss:0.632082
epoch 209/800,training loss:0.630512,validation loss:0.631815
epoch 210/800,training loss:0.630445,validation loss:0.631752
epoch 211/800,training loss:0.630614,validation loss:0.631670
epoch 212/800,training loss:0.630701,validation loss:0.631941
epoch 213/800,training loss:0.630521,validation loss:0.632051
epoch 214/800,training loss:0.630593,validation loss:0.631895
epoch 215/800,training loss:0.630465,validation loss:0.631967
epoch 216/800,training loss:0.630360,validation loss:0.632084
epoch 217/800,training loss:0.630511,validation loss:0.631746
epoch 218/800,training loss:0.630332,validation loss:0.631603
epoch 219/800,training loss:0.630219,validation loss:0.631739
epoch 220/800,training loss:0.630194,validation loss:0.631701
epoch 221/800,training loss:0.630063,validation loss:0.631434
epoch 222/800,training loss:0.630148,validation loss:0.631519
epoch 223/800,training loss:0.630094,validation loss:0.631865
epoch 224/800,training loss:0.629916,validation loss:0.631236
epoch 225/800,training loss:0.629980,validation loss:0.631521
epoch 226/800,training loss:0.629748,validation loss:0.631585
epoch 227/800,training loss:0.629705,validation loss:0.631599
epoch 228/800,training loss:0.629829,validation loss:0.631477
epoch 229/800,training loss:0.629939,validation loss:0.631367
epoch 230/800,training loss:0.629795,validation loss:0.631397
epoch 231/800,training loss:0.629820,validation loss:0.631358
epoch 232/800,training loss:0.629646,validation loss:0.631162
epoch 233/800,training loss:0.629553,validation loss:0.631229
epoch 234/800,training loss:0.629685,validation loss:0.631159
epoch 235/800,training loss:0.629306,validation loss:0.631205
epoch 236/800,training loss:0.629435,validation loss:0.631135
epoch 237/800,training loss:0.629414,validation loss:0.631079
epoch 238/800,training loss:0.629337,validation loss:0.630945
epoch 239/800,training loss:0.629383,validation loss:0.630970
epoch 240/800,training loss:0.629321,validation loss:0.631125
epoch 241/800,training loss:0.629251,validation loss:0.630827
epoch 242/800,training loss:0.629212,validation loss:0.630739
epoch 243/800,training loss:0.629214,validation loss:0.630881
epoch 244/800,training loss:0.629284,validation loss:0.630914
epoch 245/800,training loss:0.628933,validation loss:0.630769
epoch 246/800,training loss:0.628945,validation loss:0.630822
epoch 247/800,training loss:0.628969,validation loss:0.630968
epoch 248/800,training loss:0.628831,validation loss:0.630771
epoch 249/800,training loss:0.628991,validation loss:0.630941
epoch 250/800,training loss:0.628881,validation loss:0.630838
epoch 251/800,training loss:0.628841,validation loss:0.630785
epoch 252/800,training loss:0.628794,validation loss:0.630765
epoch 253/800,training loss:0.628689,validation loss:0.630777
epoch 254/800,training loss:0.628773,validation loss:0.630740
epoch 255/800,training loss:0.628802,validation loss:0.630599
epoch 256/800,training loss:0.628704,validation loss:0.630685
epoch 257/800,training loss:0.628714,validation loss:0.630607
epoch 258/800,training loss:0.628393,validation loss:0.630599
epoch 259/800,training loss:0.628423,validation loss:0.630637
epoch 260/800,training loss:0.628474,validation loss:0.630499
epoch 261/800,training loss:0.628488,validation loss:0.630536
epoch 262/800,training loss:0.628372,validation loss:0.630508
epoch 263/800,training loss:0.628310,validation loss:0.630250
epoch 264/800,training loss:0.628331,validation loss:0.630597
epoch 265/800,training loss:0.628251,validation loss:0.630277
epoch 266/800,training loss:0.628258,validation loss:0.630258
epoch 267/800,training loss:0.628182,validation loss:0.630417
epoch 268/800,training loss:0.628081,validation loss:0.630343
epoch 269/800,training loss:0.628052,validation loss:0.630336
epoch 270/800,training loss:0.628111,validation loss:0.630254
epoch 271/800,training loss:0.628020,validation loss:0.630302
epoch 272/800,training loss:0.627913,validation loss:0.629952
epoch 273/800,training loss:0.627981,validation loss:0.630033
epoch 274/800,training loss:0.628122,validation loss:0.630311
epoch 275/800,training loss:0.627875,validation loss:0.630231
epoch 276/800,training loss:0.627900,validation loss:0.630224
epoch 277/800,training loss:0.627668,validation loss:0.630195
epoch 278/800,training loss:0.627744,validation loss:0.630049
epoch 279/800,training loss:0.627888,validation loss:0.630012
epoch 280/800,training loss:0.627667,validation loss:0.629900
epoch 281/800,training loss:0.627699,validation loss:0.629862
epoch 282/800,training loss:0.627606,validation loss:0.629613
epoch 283/800,training loss:0.627646,validation loss:0.629911
epoch 284/800,training loss:0.627732,validation loss:0.629854
epoch 285/800,training loss:0.627480,validation loss:0.630296
epoch 286/800,training loss:0.627466,validation loss:0.629619
epoch 287/800,training loss:0.627507,validation loss:0.629775
epoch 288/800,training loss:0.627552,validation loss:0.629825
epoch 289/800,training loss:0.627469,validation loss:0.629743
epoch 290/800,training loss:0.627429,validation loss:0.629713
epoch 291/800,training loss:0.627578,validation loss:0.629775
epoch 292/800,training loss:0.627339,validation loss:0.629573
epoch 293/800,training loss:0.627089,validation loss:0.629740
epoch 294/800,training loss:0.627324,validation loss:0.629663
epoch 295/800,training loss:0.627123,validation loss:0.629332
epoch 296/800,training loss:0.627356,validation loss:0.629478
epoch 297/800,training loss:0.627209,validation loss:0.629627
epoch 298/800,training loss:0.627112,validation loss:0.629680
epoch 299/800,training loss:0.627336,validation loss:0.629341
epoch 300/800,training loss:0.627004,validation loss:0.629592
epoch 301/800,training loss:0.627001,validation loss:0.629562
epoch 302/800,training loss:0.626810,validation loss:0.629313
epoch 303/800,training loss:0.626884,validation loss:0.629421
epoch 304/800,training loss:0.626625,validation loss:0.629237
epoch 305/800,training loss:0.626911,validation loss:0.629345
epoch 306/800,training loss:0.626860,validation loss:0.629479
epoch 307/800,training loss:0.626804,validation loss:0.629137
epoch 308/800,training loss:0.626567,validation loss:0.629315
epoch 309/800,training loss:0.626867,validation loss:0.629235
epoch 310/800,training loss:0.626754,validation loss:0.629304
epoch 311/800,training loss:0.626674,validation loss:0.629606
epoch 312/800,training loss:0.626596,validation loss:0.629291
epoch 313/800,training loss:0.626466,validation loss:0.628997
epoch 314/800,training loss:0.626663,validation loss:0.629349
epoch 315/800,training loss:0.626347,validation loss:0.629293
epoch 316/800,training loss:0.626513,validation loss:0.629173
epoch 317/800,training loss:0.626508,validation loss:0.629122
epoch 318/800,training loss:0.626577,validation loss:0.629381
epoch 319/800,training loss:0.626624,validation loss:0.628982
epoch 320/800,training loss:0.626336,validation loss:0.629093
epoch 321/800,training loss:0.626255,validation loss:0.629227
epoch 322/800,training loss:0.626552,validation loss:0.629256
epoch 323/800,training loss:0.626280,validation loss:0.629109
epoch 324/800,training loss:0.626229,validation loss:0.629223
epoch 325/800,training loss:0.626308,validation loss:0.629260
epoch 326/800,training loss:0.626214,validation loss:0.629065
epoch 327/800,training loss:0.626236,validation loss:0.628692
epoch 328/800,training loss:0.626198,validation loss:0.629070
epoch 329/800,training loss:0.626142,validation loss:0.628980
epoch 330/800,training loss:0.625990,validation loss:0.629164
epoch 331/800,training loss:0.625986,validation loss:0.629073
epoch 332/800,training loss:0.626068,validation loss:0.629029
epoch 333/800,training loss:0.626090,validation loss:0.628725
epoch 334/800,training loss:0.626059,validation loss:0.628873
epoch 335/800,training loss:0.626024,validation loss:0.629084
epoch 336/800,training loss:0.625942,validation loss:0.629012
epoch 337/800,training loss:0.625858,validation loss:0.628757
epoch 338/800,training loss:0.625824,validation loss:0.628837
epoch 339/800,training loss:0.625779,validation loss:0.628666
epoch 340/800,training loss:0.625667,validation loss:0.628695
epoch 341/800,training loss:0.625738,validation loss:0.628777
epoch 342/800,training loss:0.625536,validation loss:0.628895
epoch 343/800,training loss:0.625608,validation loss:0.628508
epoch 344/800,training loss:0.625678,validation loss:0.628908
epoch 345/800,training loss:0.625675,validation loss:0.628920
epoch 346/800,training loss:0.625653,validation loss:0.628905
epoch 347/800,training loss:0.625494,validation loss:0.628828
epoch 348/800,training loss:0.625454,validation loss:0.628970
epoch 349/800,training loss:0.625221,validation loss:0.628408
epoch 350/800,training loss:0.625269,validation loss:0.628615
epoch 351/800,training loss:0.625514,validation loss:0.628627
epoch 352/800,training loss:0.625440,validation loss:0.628469
epoch 353/800,training loss:0.625382,validation loss:0.628633
epoch 354/800,training loss:0.625441,validation loss:0.628424
epoch 355/800,training loss:0.625498,validation loss:0.628560
epoch 356/800,training loss:0.625330,validation loss:0.628533
epoch 357/800,training loss:0.625273,validation loss:0.628313
epoch 358/800,training loss:0.625284,validation loss:0.628512
epoch 359/800,training loss:0.625112,validation loss:0.628742
epoch 360/800,training loss:0.625165,validation loss:0.628445
epoch 361/800,training loss:0.625138,validation loss:0.628373
epoch 362/800,training loss:0.625172,validation loss:0.628254
epoch 363/800,training loss:0.625340,validation loss:0.628573
epoch 364/800,training loss:0.625217,validation loss:0.628446
epoch 365/800,training loss:0.625225,validation loss:0.628258
epoch 366/800,training loss:0.624944,validation loss:0.628064
epoch 367/800,training loss:0.625140,validation loss:0.628511
epoch 368/800,training loss:0.624976,validation loss:0.628577
epoch 369/800,training loss:0.624900,validation loss:0.628134
epoch 370/800,training loss:0.624996,validation loss:0.628144
epoch 371/800,training loss:0.624923,validation loss:0.628183
epoch 372/800,training loss:0.624938,validation loss:0.628500
epoch 373/800,training loss:0.624932,validation loss:0.628326
epoch 374/800,training loss:0.624570,validation loss:0.628361
epoch 375/800,training loss:0.624785,validation loss:0.628133
epoch 376/800,training loss:0.624595,validation loss:0.628114
epoch 377/800,training loss:0.624734,validation loss:0.628363
epoch 378/800,training loss:0.624755,validation loss:0.628107
epoch 379/800,training loss:0.624566,validation loss:0.628424
epoch 380/800,training loss:0.624702,validation loss:0.628350
epoch 381/800,training loss:0.624546,validation loss:0.628353
epoch 382/800,training loss:0.624570,validation loss:0.628119
epoch 383/800,training loss:0.624572,validation loss:0.628227
epoch 384/800,training loss:0.624440,validation loss:0.628267
epoch 385/800,training loss:0.624361,validation loss:0.628141
epoch 386/800,training loss:0.624519,validation loss:0.628163
epoch 387/800,training loss:0.624511,validation loss:0.627970
epoch 388/800,training loss:0.624542,validation loss:0.628466
epoch 389/800,training loss:0.624509,validation loss:0.628137
epoch 390/800,training loss:0.624414,validation loss:0.628216
epoch 391/800,training loss:0.624222,validation loss:0.628183
epoch 392/800,training loss:0.624237,validation loss:0.628102
epoch 393/800,training loss:0.624253,validation loss:0.628065
epoch 394/800,training loss:0.624162,validation loss:0.627848
epoch 395/800,training loss:0.624501,validation loss:0.627800
epoch 396/800,training loss:0.624171,validation loss:0.628125
epoch 397/800,training loss:0.624151,validation loss:0.627956
epoch 398/800,training loss:0.624292,validation loss:0.627928
epoch 399/800,training loss:0.624262,validation loss:0.627936
epoch 400/800,training loss:0.623994,validation loss:0.627812
epoch 401/800,training loss:0.624018,validation loss:0.627849
epoch 402/800,training loss:0.624243,validation loss:0.628162
epoch 403/800,training loss:0.624082,validation loss:0.627947
epoch 404/800,training loss:0.624128,validation loss:0.628023
epoch 405/800,training loss:0.623988,validation loss:0.627956
epoch 406/800,training loss:0.623988,validation loss:0.627740
epoch 407/800,training loss:0.623988,validation loss:0.627977
epoch 408/800,training loss:0.623979,validation loss:0.628121
epoch 409/800,training loss:0.623868,validation loss:0.627903
epoch 410/800,training loss:0.623872,validation loss:0.628267
epoch 411/800,training loss:0.623764,validation loss:0.627933
epoch 412/800,training loss:0.623951,validation loss:0.627787
epoch 413/800,training loss:0.623691,validation loss:0.627800
epoch 414/800,training loss:0.623667,validation loss:0.627787
epoch 415/800,training loss:0.623803,validation loss:0.627827
epoch 416/800,training loss:0.623675,validation loss:0.627978
epoch 417/800,training loss:0.623646,validation loss:0.627751
epoch 418/800,training loss:0.623714,validation loss:0.627956
epoch 419/800,training loss:0.623597,validation loss:0.627885
epoch 420/800,training loss:0.623562,validation loss:0.627901
epoch 421/800,training loss:0.623560,validation loss:0.627752
epoch 422/800,training loss:0.623532,validation loss:0.627560
epoch 423/800,training loss:0.623456,validation loss:0.627611
epoch 424/800,training loss:0.623647,validation loss:0.627779
epoch 425/800,training loss:0.623414,validation loss:0.627661
epoch 426/800,training loss:0.623620,validation loss:0.627840
epoch 427/800,training loss:0.623446,validation loss:0.627665
epoch 428/800,training loss:0.623278,validation loss:0.627565
epoch 429/800,training loss:0.623242,validation loss:0.627806
epoch 430/800,training loss:0.623377,validation loss:0.627752
epoch 431/800,training loss:0.623348,validation loss:0.627491
epoch 432/800,training loss:0.623207,validation loss:0.627840
epoch 433/800,training loss:0.623422,validation loss:0.627734
epoch 434/800,training loss:0.623375,validation loss:0.627397
epoch 435/800,training loss:0.623253,validation loss:0.627341
epoch 436/800,training loss:0.623170,validation loss:0.627696
epoch 437/800,training loss:0.623300,validation loss:0.627583
epoch 438/800,training loss:0.623194,validation loss:0.627317
epoch 439/800,training loss:0.623011,validation loss:0.627384
epoch 440/800,training loss:0.623188,validation loss:0.627147
epoch 441/800,training loss:0.623167,validation loss:0.627317
epoch 442/800,training loss:0.623143,validation loss:0.627666
epoch 443/800,training loss:0.623266,validation loss:0.627688
epoch 444/800,training loss:0.622945,validation loss:0.627687
epoch 445/800,training loss:0.623033,validation loss:0.627626
epoch 446/800,training loss:0.623232,validation loss:0.627602
epoch 447/800,training loss:0.623060,validation loss:0.627725
epoch 448/800,training loss:0.622981,validation loss:0.627462
epoch 449/800,training loss:0.622980,validation loss:0.627710
epoch 450/800,training loss:0.623060,validation loss:0.627509
epoch 451/800,training loss:0.622883,validation loss:0.627551
epoch 452/800,training loss:0.622902,validation loss:0.627535
epoch 453/800,training loss:0.623131,validation loss:0.627776
epoch 454/800,training loss:0.622940,validation loss:0.627110
epoch 455/800,training loss:0.622872,validation loss:0.627284
epoch 456/800,training loss:0.622599,validation loss:0.627272
epoch 457/800,training loss:0.622973,validation loss:0.627547
epoch 458/800,training loss:0.622773,validation loss:0.627305
epoch 459/800,training loss:0.623063,validation loss:0.627397
epoch 460/800,training loss:0.622707,validation loss:0.627552
epoch 461/800,training loss:0.622735,validation loss:0.627533
epoch 462/800,training loss:0.622627,validation loss:0.627461
epoch 463/800,training loss:0.622566,validation loss:0.627331
epoch 464/800,training loss:0.622787,validation loss:0.627569
epoch 465/800,training loss:0.622631,validation loss:0.627389
epoch 466/800,training loss:0.623049,validation loss:0.627483
epoch 467/800,training loss:0.622648,validation loss:0.627210
epoch 468/800,training loss:0.622516,validation loss:0.627389
epoch 469/800,training loss:0.622746,validation loss:0.627275
epoch 470/800,training loss:0.622374,validation loss:0.627694
epoch 471/800,training loss:0.622311,validation loss:0.627478
epoch 472/800,training loss:0.622297,validation loss:0.627491
epoch 473/800,training loss:0.622400,validation loss:0.627248
epoch 474/800,training loss:0.622676,validation loss:0.627326
epoch 475/800,training loss:0.622482,validation loss:0.627191
epoch 476/800,training loss:0.622434,validation loss:0.627645
epoch 477/800,training loss:0.622415,validation loss:0.627302
epoch 478/800,training loss:0.622469,validation loss:0.627153
epoch 479/800,training loss:0.622420,validation loss:0.627244
epoch 480/800,training loss:0.622542,validation loss:0.627277
epoch 481/800,training loss:0.622371,validation loss:0.627130
epoch 482/800,training loss:0.622242,validation loss:0.627251
epoch 483/800,training loss:0.622315,validation loss:0.627144
epoch 484/800,training loss:0.622393,validation loss:0.627197
epoch 485/800,training loss:0.622272,validation loss:0.627283
epoch 486/800,training loss:0.622149,validation loss:0.627267
epoch 487/800,training loss:0.622070,validation loss:0.627238
epoch 488/800,training loss:0.622235,validation loss:0.627109
epoch 489/800,training loss:0.622268,validation loss:0.627306
epoch 490/800,training loss:0.622280,validation loss:0.627016
epoch 491/800,training loss:0.622070,validation loss:0.627331
epoch 492/800,training loss:0.621913,validation loss:0.627029
epoch 493/800,training loss:0.621938,validation loss:0.627053
epoch 494/800,training loss:0.621983,validation loss:0.627346
epoch 495/800,training loss:0.621965,validation loss:0.627023
epoch 496/800,training loss:0.622104,validation loss:0.627000
epoch 497/800,training loss:0.622022,validation loss:0.627242
epoch 498/800,training loss:0.621984,validation loss:0.627321
epoch 499/800,training loss:0.622082,validation loss:0.627120
epoch 500/800,training loss:0.621736,validation loss:0.627031
epoch 501/800,training loss:0.621775,validation loss:0.627366
epoch 502/800,training loss:0.621888,validation loss:0.626991
epoch 503/800,training loss:0.622033,validation loss:0.627363
epoch 504/800,training loss:0.621982,validation loss:0.627502
epoch 505/800,training loss:0.621761,validation loss:0.627089
epoch 506/800,training loss:0.621886,validation loss:0.627266
epoch 507/800,training loss:0.621796,validation loss:0.627247
epoch 508/800,training loss:0.621754,validation loss:0.626893
epoch 509/800,training loss:0.621854,validation loss:0.626976
epoch 510/800,training loss:0.621912,validation loss:0.627150
epoch 511/800,training loss:0.621784,validation loss:0.626840
epoch 512/800,training loss:0.621745,validation loss:0.627030
epoch 513/800,training loss:0.621790,validation loss:0.627104
epoch 514/800,training loss:0.621870,validation loss:0.626909
epoch 515/800,training loss:0.621465,validation loss:0.627042
epoch 516/800,training loss:0.621675,validation loss:0.626881
epoch 517/800,training loss:0.621395,validation loss:0.627069
epoch 518/800,training loss:0.621779,validation loss:0.627128
epoch 519/800,training loss:0.621651,validation loss:0.626910
epoch 520/800,training loss:0.621639,validation loss:0.627015
epoch 521/800,training loss:0.621692,validation loss:0.627187
epoch 522/800,training loss:0.621656,validation loss:0.626942
epoch 523/800,training loss:0.621577,validation loss:0.627074
epoch 524/800,training loss:0.621569,validation loss:0.627408
epoch 525/800,training loss:0.621406,validation loss:0.626929
epoch 526/800,training loss:0.621416,validation loss:0.627048
epoch 527/800,training loss:0.621435,validation loss:0.626898
epoch 528/800,training loss:0.621385,validation loss:0.627074
epoch 529/800,training loss:0.621383,validation loss:0.626820
epoch 530/800,training loss:0.621562,validation loss:0.626968
epoch 531/800,training loss:0.621373,validation loss:0.627175
epoch 532/800,training loss:0.621383,validation loss:0.627000
epoch 533/800,training loss:0.621488,validation loss:0.626928
epoch 534/800,training loss:0.621104,validation loss:0.627159
epoch 535/800,training loss:0.621407,validation loss:0.626865
epoch 536/800,training loss:0.621497,validation loss:0.626628
epoch 537/800,training loss:0.621020,validation loss:0.627230
epoch 538/800,training loss:0.621465,validation loss:0.627165
epoch 539/800,training loss:0.621383,validation loss:0.627225
epoch 540/800,training loss:0.621528,validation loss:0.627022
epoch 541/800,training loss:0.621255,validation loss:0.626859
epoch 542/800,training loss:0.621099,validation loss:0.626650
epoch 543/800,training loss:0.621036,validation loss:0.626948
epoch 544/800,training loss:0.621235,validation loss:0.626795
epoch 545/800,training loss:0.620993,validation loss:0.627209
epoch 546/800,training loss:0.621300,validation loss:0.626976
epoch 547/800,training loss:0.621320,validation loss:0.626980
epoch 548/800,training loss:0.621046,validation loss:0.627009
epoch 549/800,training loss:0.620990,validation loss:0.627078
epoch 550/800,training loss:0.621097,validation loss:0.626921
epoch 551/800,training loss:0.621133,validation loss:0.626741
epoch 552/800,training loss:0.621119,validation loss:0.627001
epoch 553/800,training loss:0.621021,validation loss:0.626652
epoch 554/800,training loss:0.621005,validation loss:0.627037
epoch 555/800,training loss:0.621093,validation loss:0.627305
epoch 556/800,training loss:0.621001,validation loss:0.627029
epoch 557/800,training loss:0.620881,validation loss:0.626755
epoch 558/800,training loss:0.620987,validation loss:0.626887
epoch 559/800,training loss:0.621059,validation loss:0.626963
epoch 560/800,training loss:0.621093,validation loss:0.627007
epoch 561/800,training loss:0.620815,validation loss:0.626917
epoch 562/800,training loss:0.620808,validation loss:0.626847
epoch 563/800,training loss:0.620867,validation loss:0.626938
epoch 564/800,training loss:0.620806,validation loss:0.626720
epoch 565/800,training loss:0.620793,validation loss:0.626613
epoch 566/800,training loss:0.620908,validation loss:0.626850
epoch 567/800,training loss:0.620737,validation loss:0.626945
epoch 568/800,training loss:0.620767,validation loss:0.626927
epoch 569/800,training loss:0.620596,validation loss:0.626960
epoch 570/800,training loss:0.620732,validation loss:0.626600
epoch 571/800,training loss:0.620967,validation loss:0.626606
epoch 572/800,training loss:0.620781,validation loss:0.626726
epoch 573/800,training loss:0.620689,validation loss:0.626900
epoch 574/800,training loss:0.620510,validation loss:0.627010
epoch 575/800,training loss:0.620794,validation loss:0.626904
epoch 576/800,training loss:0.620574,validation loss:0.626924
epoch 577/800,training loss:0.620762,validation loss:0.626742
epoch 578/800,training loss:0.620740,validation loss:0.626917
epoch 579/800,training loss:0.620747,validation loss:0.626650
epoch 580/800,training loss:0.620538,validation loss:0.626864
epoch 581/800,training loss:0.620523,validation loss:0.626493
epoch 582/800,training loss:0.620455,validation loss:0.627148
epoch 583/800,training loss:0.620457,validation loss:0.626465
epoch 584/800,training loss:0.620495,validation loss:0.626802
epoch 585/800,training loss:0.620386,validation loss:0.627046
epoch 586/800,training loss:0.620591,validation loss:0.626852
epoch 587/800,training loss:0.620468,validation loss:0.626761
epoch 588/800,training loss:0.620433,validation loss:0.626562
epoch 589/800,training loss:0.620745,validation loss:0.626830
epoch 590/800,training loss:0.620340,validation loss:0.626521
epoch 591/800,training loss:0.620474,validation loss:0.626696
epoch 592/800,training loss:0.620496,validation loss:0.626902
epoch 593/800,training loss:0.620483,validation loss:0.626734
epoch 594/800,training loss:0.620410,validation loss:0.626632
epoch 595/800,training loss:0.620450,validation loss:0.626614
epoch 596/800,training loss:0.620457,validation loss:0.626668
epoch 597/800,training loss:0.620243,validation loss:0.626464
epoch 598/800,training loss:0.620323,validation loss:0.627214
epoch 599/800,training loss:0.620412,validation loss:0.626739
epoch 600/800,training loss:0.620290,validation loss:0.626463
epoch 601/800,training loss:0.620183,validation loss:0.627103
epoch 602/800,training loss:0.620030,validation loss:0.626527
epoch 603/800,training loss:0.620292,validation loss:0.626595
epoch 604/800,training loss:0.620423,validation loss:0.626995
epoch 605/800,training loss:0.620192,validation loss:0.626798
epoch 606/800,training loss:0.620238,validation loss:0.626631
epoch 607/800,training loss:0.620618,validation loss:0.626531
epoch 608/800,training loss:0.620276,validation loss:0.626793
epoch 609/800,training loss:0.620297,validation loss:0.626599
epoch 610/800,training loss:0.620211,validation loss:0.626821
epoch 611/800,training loss:0.620110,validation loss:0.627139
epoch 612/800,training loss:0.620293,validation loss:0.627122
epoch 613/800,training loss:0.620021,validation loss:0.626847
epoch 614/800,training loss:0.619945,validation loss:0.627026
epoch 615/800,training loss:0.620027,validation loss:0.627125
epoch 616/800,training loss:0.619971,validation loss:0.627010
epoch 617/800,training loss:0.620137,validation loss:0.626850
epoch 618/800,training loss:0.619992,validation loss:0.626760
epoch 619/800,training loss:0.619876,validation loss:0.626901
epoch 620/800,training loss:0.619995,validation loss:0.626643
epoch 621/800,training loss:0.619887,validation loss:0.626472
epoch 622/800,training loss:0.620067,validation loss:0.626565
epoch 623/800,training loss:0.620129,validation loss:0.626685
epoch 624/800,training loss:0.620128,validation loss:0.626857
epoch 625/800,training loss:0.619790,validation loss:0.626821
epoch 626/800,training loss:0.619897,validation loss:0.626401
epoch 627/800,training loss:0.619938,validation loss:0.626544
epoch 628/800,training loss:0.619872,validation loss:0.626761
epoch 629/800,training loss:0.620003,validation loss:0.626548
epoch 630/800,training loss:0.619679,validation loss:0.626578
epoch 631/800,training loss:0.619665,validation loss:0.626787
epoch 632/800,training loss:0.619568,validation loss:0.626689
epoch 633/800,training loss:0.619978,validation loss:0.626791
epoch 634/800,training loss:0.619907,validation loss:0.626420
epoch 635/800,training loss:0.619924,validation loss:0.627019
epoch 636/800,training loss:0.619540,validation loss:0.626372
epoch 637/800,training loss:0.619804,validation loss:0.626815
epoch 638/800,training loss:0.619726,validation loss:0.626804
epoch 639/800,training loss:0.619615,validation loss:0.626432
epoch 640/800,training loss:0.619796,validation loss:0.626737
epoch 641/800,training loss:0.619608,validation loss:0.626769
epoch 642/800,training loss:0.619824,validation loss:0.626785
epoch 643/800,training loss:0.619551,validation loss:0.626537
epoch 644/800,training loss:0.619699,validation loss:0.626777
epoch 645/800,training loss:0.619659,validation loss:0.626524
epoch 646/800,training loss:0.619614,validation loss:0.626643
epoch 647/800,training loss:0.619519,validation loss:0.626688
epoch 648/800,training loss:0.619866,validation loss:0.626434
epoch 649/800,training loss:0.619510,validation loss:0.626741
epoch 650/800,training loss:0.619599,validation loss:0.626538
epoch 651/800,training loss:0.619438,validation loss:0.626741
epoch 652/800,training loss:0.619303,validation loss:0.626647
epoch 653/800,training loss:0.619773,validation loss:0.626893
epoch 654/800,training loss:0.619451,validation loss:0.626450
epoch 655/800,training loss:0.619250,validation loss:0.626566
epoch 656/800,training loss:0.619346,validation loss:0.626670
epoch 657/800,training loss:0.619572,validation loss:0.627054
epoch 658/800,training loss:0.619591,validation loss:0.627088
epoch 659/800,training loss:0.619610,validation loss:0.626840
epoch 660/800,training loss:0.619549,validation loss:0.626525
epoch 661/800,training loss:0.619348,validation loss:0.626539
epoch 662/800,training loss:0.619558,validation loss:0.626784
epoch 663/800,training loss:0.619329,validation loss:0.626633
epoch 664/800,training loss:0.619410,validation loss:0.626371
epoch 665/800,training loss:0.619484,validation loss:0.626565
epoch 666/800,training loss:0.619523,validation loss:0.626700
epoch 667/800,training loss:0.619389,validation loss:0.626669
epoch 668/800,training loss:0.619353,validation loss:0.626551
epoch 669/800,training loss:0.619276,validation loss:0.626576
epoch 670/800,training loss:0.619483,validation loss:0.626719
epoch 671/800,training loss:0.619189,validation loss:0.626836
epoch 672/800,training loss:0.619351,validation loss:0.626584
epoch 673/800,training loss:0.619416,validation loss:0.626870
epoch 674/800,training loss:0.619209,validation loss:0.626441
epoch 675/800,training loss:0.619204,validation loss:0.626368
epoch 676/800,training loss:0.619149,validation loss:0.626576
epoch 677/800,training loss:0.619106,validation loss:0.626590
epoch 678/800,training loss:0.619345,validation loss:0.626600
epoch 679/800,training loss:0.619147,validation loss:0.626670
epoch 680/800,training loss:0.618995,validation loss:0.626578
epoch 681/800,training loss:0.619129,validation loss:0.626765
epoch 682/800,training loss:0.619155,validation loss:0.626620
epoch 683/800,training loss:0.619076,validation loss:0.626552
epoch 684/800,training loss:0.619193,validation loss:0.626527
epoch 685/800,training loss:0.618974,validation loss:0.626727
epoch 686/800,training loss:0.619099,validation loss:0.626577
epoch 687/800,training loss:0.619086,validation loss:0.626972
epoch 688/800,training loss:0.618973,validation loss:0.626774
epoch 689/800,training loss:0.619099,validation loss:0.626776
epoch 690/800,training loss:0.619124,validation loss:0.626821
epoch 691/800,training loss:0.619034,validation loss:0.626398
epoch 692/800,training loss:0.619006,validation loss:0.626692
epoch 693/800,training loss:0.618913,validation loss:0.626734
epoch 694/800,training loss:0.618966,validation loss:0.626241
epoch 695/800,training loss:0.619120,validation loss:0.626431
epoch 696/800,training loss:0.618793,validation loss:0.626402
epoch 697/800,training loss:0.619075,validation loss:0.626418
epoch 698/800,training loss:0.619141,validation loss:0.626517
epoch 699/800,training loss:0.618927,validation loss:0.626744
epoch 700/800,training loss:0.618760,validation loss:0.626654
epoch 701/800,training loss:0.618920,validation loss:0.626584
epoch 702/800,training loss:0.618769,validation loss:0.626755
epoch 703/800,training loss:0.618944,validation loss:0.626417
epoch 704/800,training loss:0.619138,validation loss:0.626850
epoch 705/800,training loss:0.618915,validation loss:0.626822
epoch 706/800,training loss:0.618713,validation loss:0.626764
epoch 707/800,training loss:0.618870,validation loss:0.626202
epoch 708/800,training loss:0.618627,validation loss:0.626818
epoch 709/800,training loss:0.618742,validation loss:0.626646
epoch 710/800,training loss:0.618687,validation loss:0.626666
epoch 711/800,training loss:0.618719,validation loss:0.626817
epoch 712/800,training loss:0.618765,validation loss:0.626636
epoch 713/800,training loss:0.618543,validation loss:0.626519
epoch 714/800,training loss:0.618589,validation loss:0.626635
epoch 715/800,training loss:0.618875,validation loss:0.626747
epoch 716/800,training loss:0.618880,validation loss:0.626680
epoch 717/800,training loss:0.618580,validation loss:0.626543
epoch 718/800,training loss:0.618386,validation loss:0.626863
epoch 719/800,training loss:0.618690,validation loss:0.626664
epoch 720/800,training loss:0.618886,validation loss:0.626534
epoch 721/800,training loss:0.618494,validation loss:0.626212
epoch 722/800,training loss:0.618530,validation loss:0.626720
epoch 723/800,training loss:0.618588,validation loss:0.626706
epoch 724/800,training loss:0.618764,validation loss:0.626549
epoch 725/800,training loss:0.618658,validation loss:0.626445
epoch 726/800,training loss:0.618413,validation loss:0.626410
epoch 727/800,training loss:0.618450,validation loss:0.626531
epoch 728/800,training loss:0.618706,validation loss:0.626463
epoch 729/800,training loss:0.618718,validation loss:0.626401
epoch 730/800,training loss:0.618650,validation loss:0.626966
epoch 731/800,training loss:0.618624,validation loss:0.626640
epoch 732/800,training loss:0.618673,validation loss:0.626265
epoch 733/800,training loss:0.618526,validation loss:0.626562
epoch 734/800,training loss:0.618506,validation loss:0.626639
epoch 735/800,training loss:0.618349,validation loss:0.626526
epoch 736/800,training loss:0.618532,validation loss:0.626808
epoch 737/800,training loss:0.618624,validation loss:0.626514
epoch 738/800,training loss:0.618463,validation loss:0.626470
epoch 739/800,training loss:0.618402,validation loss:0.626480
epoch 740/800,training loss:0.618650,validation loss:0.626719
epoch 741/800,training loss:0.618494,validation loss:0.626753
epoch 742/800,training loss:0.618352,validation loss:0.626781
epoch 743/800,training loss:0.618202,validation loss:0.626591
epoch 744/800,training loss:0.618423,validation loss:0.626675
epoch 745/800,training loss:0.618417,validation loss:0.626512
epoch 746/800,training loss:0.618426,validation loss:0.626441
epoch 747/800,training loss:0.618707,validation loss:0.626818
epoch 748/800,training loss:0.618297,validation loss:0.626678
epoch 749/800,training loss:0.618356,validation loss:0.626505
epoch 750/800,training loss:0.618557,validation loss:0.626775
epoch 751/800,training loss:0.618373,validation loss:0.626662
epoch 752/800,training loss:0.618381,validation loss:0.626464
epoch 753/800,training loss:0.618295,validation loss:0.626414
epoch 754/800,training loss:0.618455,validation loss:0.626634
epoch 755/800,training loss:0.618285,validation loss:0.626498
epoch 756/800,training loss:0.618222,validation loss:0.626640
epoch 757/800,training loss:0.618151,validation loss:0.626386
epoch 758/800,training loss:0.618148,validation loss:0.626711
epoch 759/800,training loss:0.618115,validation loss:0.626584
epoch 760/800,training loss:0.618388,validation loss:0.626539
epoch 761/800,training loss:0.617912,validation loss:0.626476
epoch 762/800,training loss:0.618262,validation loss:0.626661
epoch 763/800,training loss:0.618086,validation loss:0.626653
epoch 764/800,training loss:0.618222,validation loss:0.626641
epoch 765/800,training loss:0.618293,validation loss:0.626651
epoch 766/800,training loss:0.618084,validation loss:0.626349
epoch 767/800,training loss:0.618343,validation loss:0.626200
epoch 768/800,training loss:0.618390,validation loss:0.626426
epoch 769/800,training loss:0.618083,validation loss:0.626645
epoch 770/800,training loss:0.618260,validation loss:0.626679
epoch 771/800,training loss:0.618142,validation loss:0.626434
epoch 772/800,training loss:0.618080,validation loss:0.626395
epoch 773/800,training loss:0.618004,validation loss:0.626665
epoch 774/800,training loss:0.618076,validation loss:0.626775
epoch 775/800,training loss:0.617974,validation loss:0.626780
epoch 776/800,training loss:0.617902,validation loss:0.626418
epoch 777/800,training loss:0.617802,validation loss:0.626343
epoch 778/800,training loss:0.618038,validation loss:0.626732
epoch 779/800,training loss:0.618012,validation loss:0.626656
epoch 780/800,training loss:0.618197,validation loss:0.626187
epoch 781/800,training loss:0.617893,validation loss:0.626265
epoch 782/800,training loss:0.617845,validation loss:0.626556
epoch 783/800,training loss:0.617893,validation loss:0.626489
epoch 784/800,training loss:0.618013,validation loss:0.626726
epoch 785/800,training loss:0.617867,validation loss:0.626655
epoch 786/800,training loss:0.617880,validation loss:0.626878
epoch 787/800,training loss:0.618009,validation loss:0.626502
epoch 788/800,training loss:0.618167,validation loss:0.626312
epoch 789/800,training loss:0.617743,validation loss:0.626641
epoch 790/800,training loss:0.617826,validation loss:0.626279
epoch 791/800,training loss:0.618018,validation loss:0.626350
epoch 792/800,training loss:0.618175,validation loss:0.626760
epoch 793/800,training loss:0.617731,validation loss:0.626363
epoch 794/800,training loss:0.617802,validation loss:0.626604
epoch 795/800,training loss:0.617920,validation loss:0.626667
epoch 796/800,training loss:0.617808,validation loss:0.626793
epoch 797/800,training loss:0.617840,validation loss:0.626443
epoch 798/800,training loss:0.617752,validation loss:0.626628
epoch 799/800,training loss:0.617496,validation loss:0.626561
Finished. Saving the model to /h/172/shawnlyu/projects/machine_learning/CSC2515Dota2DraftPredictionProject/algorithms/shawn/exp/fc_12.batch.pth
The best validation accuracy occurs at 0th epoch