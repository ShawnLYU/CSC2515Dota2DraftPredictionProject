epoch 0/600,training loss:0.692026,validation loss:0.690468
epoch 1/600,training loss:0.690091,validation loss:0.689975
epoch 2/600,training loss:0.689635,validation loss:0.689528
epoch 3/600,training loss:0.689186,validation loss:0.689162
epoch 4/600,training loss:0.688716,validation loss:0.688540
epoch 5/600,training loss:0.688130,validation loss:0.687838
epoch 6/600,training loss:0.687335,validation loss:0.687075
epoch 7/600,training loss:0.686382,validation loss:0.685911
epoch 8/600,training loss:0.684990,validation loss:0.684263
epoch 9/600,training loss:0.683163,validation loss:0.682104
epoch 10/600,training loss:0.680505,validation loss:0.679175
epoch 11/600,training loss:0.677154,validation loss:0.675434
epoch 12/600,training loss:0.673058,validation loss:0.670572
epoch 13/600,training loss:0.668585,validation loss:0.666473
epoch 14/600,training loss:0.664311,validation loss:0.662069
epoch 15/600,training loss:0.660889,validation loss:0.659088
epoch 16/600,training loss:0.657645,validation loss:0.656331
epoch 17/600,training loss:0.655284,validation loss:0.654676
epoch 18/600,training loss:0.653240,validation loss:0.652570
epoch 19/600,training loss:0.651510,validation loss:0.650838
epoch 20/600,training loss:0.650363,validation loss:0.649949
epoch 21/600,training loss:0.649088,validation loss:0.648753
epoch 22/600,training loss:0.648046,validation loss:0.647730
epoch 23/600,training loss:0.647070,validation loss:0.646996
epoch 24/600,training loss:0.646450,validation loss:0.646052
epoch 25/600,training loss:0.645527,validation loss:0.645010
epoch 26/600,training loss:0.645070,validation loss:0.644652
epoch 27/600,training loss:0.644265,validation loss:0.644301
epoch 28/600,training loss:0.643915,validation loss:0.643469
epoch 29/600,training loss:0.643466,validation loss:0.643621
epoch 30/600,training loss:0.643143,validation loss:0.642743
epoch 31/600,training loss:0.642375,validation loss:0.642553
epoch 32/600,training loss:0.642187,validation loss:0.642246
epoch 33/600,training loss:0.641724,validation loss:0.641691
epoch 34/600,training loss:0.641258,validation loss:0.641412
epoch 35/600,training loss:0.640823,validation loss:0.641090
epoch 36/600,training loss:0.640692,validation loss:0.640634
epoch 37/600,training loss:0.640313,validation loss:0.640382
epoch 38/600,training loss:0.640058,validation loss:0.640340
epoch 39/600,training loss:0.639823,validation loss:0.639901
epoch 40/600,training loss:0.639673,validation loss:0.639672
epoch 41/600,training loss:0.639429,validation loss:0.639318
epoch 42/600,training loss:0.639213,validation loss:0.639305
epoch 43/600,training loss:0.638815,validation loss:0.639167
epoch 44/600,training loss:0.638683,validation loss:0.638914
epoch 45/600,training loss:0.638736,validation loss:0.638706
epoch 46/600,training loss:0.638433,validation loss:0.638513
epoch 47/600,training loss:0.638222,validation loss:0.638407
epoch 48/600,training loss:0.638103,validation loss:0.638316
epoch 49/600,training loss:0.637891,validation loss:0.638176
epoch 50/600,training loss:0.637548,validation loss:0.638129
epoch 51/600,training loss:0.637637,validation loss:0.637730
epoch 52/600,training loss:0.637534,validation loss:0.637621
epoch 53/600,training loss:0.637448,validation loss:0.637679
epoch 54/600,training loss:0.637145,validation loss:0.637374
epoch 55/600,training loss:0.637103,validation loss:0.637347
epoch 56/600,training loss:0.636997,validation loss:0.637102
epoch 57/600,training loss:0.636765,validation loss:0.637201
epoch 58/600,training loss:0.636578,validation loss:0.637087
epoch 59/600,training loss:0.636561,validation loss:0.636934
epoch 60/600,training loss:0.636457,validation loss:0.636478
epoch 61/600,training loss:0.636281,validation loss:0.636796
epoch 62/600,training loss:0.636116,validation loss:0.636354
epoch 63/600,training loss:0.636165,validation loss:0.636521
epoch 64/600,training loss:0.635977,validation loss:0.636529
epoch 65/600,training loss:0.636039,validation loss:0.636034
epoch 66/600,training loss:0.635869,validation loss:0.636128
epoch 67/600,training loss:0.635475,validation loss:0.636259
epoch 68/600,training loss:0.635704,validation loss:0.636051
epoch 69/600,training loss:0.635506,validation loss:0.636279
epoch 70/600,training loss:0.635557,validation loss:0.635985
epoch 71/600,training loss:0.635467,validation loss:0.635812
epoch 72/600,training loss:0.635312,validation loss:0.635907
epoch 73/600,training loss:0.635242,validation loss:0.635639
epoch 74/600,training loss:0.635020,validation loss:0.635547
epoch 75/600,training loss:0.635245,validation loss:0.635370
epoch 76/600,training loss:0.635144,validation loss:0.635424
epoch 77/600,training loss:0.634915,validation loss:0.635321
epoch 78/600,training loss:0.635142,validation loss:0.635398
epoch 79/600,training loss:0.634776,validation loss:0.635313
epoch 80/600,training loss:0.634560,validation loss:0.635319
epoch 81/600,training loss:0.634731,validation loss:0.635240
epoch 82/600,training loss:0.634548,validation loss:0.635382
epoch 83/600,training loss:0.634488,validation loss:0.635194
epoch 84/600,training loss:0.634363,validation loss:0.635007
epoch 85/600,training loss:0.634272,validation loss:0.634728
epoch 86/600,training loss:0.634444,validation loss:0.634999
epoch 87/600,training loss:0.634106,validation loss:0.634552
epoch 88/600,training loss:0.634082,validation loss:0.634736
epoch 89/600,training loss:0.634030,validation loss:0.634620
epoch 90/600,training loss:0.634102,validation loss:0.634615
epoch 91/600,training loss:0.633933,validation loss:0.634427
epoch 92/600,training loss:0.633768,validation loss:0.634574
epoch 93/600,training loss:0.633951,validation loss:0.634586
epoch 94/600,training loss:0.633836,validation loss:0.634596
epoch 95/600,training loss:0.633754,validation loss:0.634484
epoch 96/600,training loss:0.633666,validation loss:0.634523
epoch 97/600,training loss:0.633565,validation loss:0.634181
epoch 98/600,training loss:0.633598,validation loss:0.634215
epoch 99/600,training loss:0.633366,validation loss:0.634176
epoch 100/600,training loss:0.633301,validation loss:0.634085
epoch 101/600,training loss:0.633418,validation loss:0.634327
epoch 102/600,training loss:0.633340,validation loss:0.634328
epoch 103/600,training loss:0.633342,validation loss:0.634109
epoch 104/600,training loss:0.633169,validation loss:0.633960
epoch 105/600,training loss:0.633178,validation loss:0.633900
epoch 106/600,training loss:0.632936,validation loss:0.633975
epoch 107/600,training loss:0.633311,validation loss:0.633795
epoch 108/600,training loss:0.633126,validation loss:0.633780
epoch 109/600,training loss:0.632891,validation loss:0.633654
epoch 110/600,training loss:0.632831,validation loss:0.633820
epoch 111/600,training loss:0.632907,validation loss:0.633833
epoch 112/600,training loss:0.632766,validation loss:0.633740
epoch 113/600,training loss:0.632865,validation loss:0.633654
epoch 114/600,training loss:0.632760,validation loss:0.633304
epoch 115/600,training loss:0.632648,validation loss:0.633423
epoch 116/600,training loss:0.632417,validation loss:0.633439
epoch 117/600,training loss:0.632620,validation loss:0.633222
epoch 118/600,training loss:0.632574,validation loss:0.633368
epoch 119/600,training loss:0.632582,validation loss:0.633163
epoch 120/600,training loss:0.632629,validation loss:0.633509
epoch 121/600,training loss:0.632109,validation loss:0.633250
epoch 122/600,training loss:0.632448,validation loss:0.633012
epoch 123/600,training loss:0.632187,validation loss:0.632922
epoch 124/600,training loss:0.632184,validation loss:0.633110
epoch 125/600,training loss:0.632104,validation loss:0.633138
epoch 126/600,training loss:0.632153,validation loss:0.633062
epoch 127/600,training loss:0.632091,validation loss:0.633184
epoch 128/600,training loss:0.632087,validation loss:0.632742
epoch 129/600,training loss:0.631867,validation loss:0.632949
epoch 130/600,training loss:0.632007,validation loss:0.632809
epoch 131/600,training loss:0.631792,validation loss:0.632752
epoch 132/600,training loss:0.631664,validation loss:0.632825
epoch 133/600,training loss:0.631697,validation loss:0.632601
epoch 134/600,training loss:0.631603,validation loss:0.632764
epoch 135/600,training loss:0.631686,validation loss:0.632493
epoch 136/600,training loss:0.631572,validation loss:0.632691
epoch 137/600,training loss:0.631550,validation loss:0.632457
epoch 138/600,training loss:0.631488,validation loss:0.632649
epoch 139/600,training loss:0.631512,validation loss:0.632648
epoch 140/600,training loss:0.631583,validation loss:0.632479
epoch 141/600,training loss:0.631393,validation loss:0.632386
epoch 142/600,training loss:0.631212,validation loss:0.632280
epoch 143/600,training loss:0.631264,validation loss:0.632276
epoch 144/600,training loss:0.631229,validation loss:0.632330
epoch 145/600,training loss:0.631222,validation loss:0.632201
epoch 146/600,training loss:0.631109,validation loss:0.632368
epoch 147/600,training loss:0.631252,validation loss:0.631963
epoch 148/600,training loss:0.631066,validation loss:0.631997
epoch 149/600,training loss:0.630850,validation loss:0.632171
epoch 150/600,training loss:0.631025,validation loss:0.632119
epoch 151/600,training loss:0.630922,validation loss:0.632188
epoch 152/600,training loss:0.630764,validation loss:0.632074
epoch 153/600,training loss:0.630887,validation loss:0.631782
epoch 154/600,training loss:0.630596,validation loss:0.631798
epoch 155/600,training loss:0.630760,validation loss:0.631933
epoch 156/600,training loss:0.630591,validation loss:0.632081
epoch 157/600,training loss:0.630902,validation loss:0.631545
epoch 158/600,training loss:0.630408,validation loss:0.631633
epoch 159/600,training loss:0.630520,validation loss:0.631981
epoch 160/600,training loss:0.630397,validation loss:0.631964
epoch 161/600,training loss:0.630331,validation loss:0.631718
epoch 162/600,training loss:0.630282,validation loss:0.631728
epoch 163/600,training loss:0.630318,validation loss:0.631674
epoch 164/600,training loss:0.630341,validation loss:0.631547
epoch 165/600,training loss:0.630263,validation loss:0.631734
epoch 166/600,training loss:0.630223,validation loss:0.631459
epoch 167/600,training loss:0.630180,validation loss:0.631220
epoch 168/600,training loss:0.630040,validation loss:0.631489
epoch 169/600,training loss:0.630092,validation loss:0.631390
epoch 170/600,training loss:0.630006,validation loss:0.631280
epoch 171/600,training loss:0.630027,validation loss:0.631219
epoch 172/600,training loss:0.629903,validation loss:0.631017
epoch 173/600,training loss:0.629909,validation loss:0.631272
epoch 174/600,training loss:0.629906,validation loss:0.631419
epoch 175/600,training loss:0.629686,validation loss:0.631113
epoch 176/600,training loss:0.629725,validation loss:0.631156
epoch 177/600,training loss:0.629506,validation loss:0.631011
epoch 178/600,training loss:0.629645,validation loss:0.630978
epoch 179/600,training loss:0.629493,validation loss:0.630869
epoch 180/600,training loss:0.629406,validation loss:0.631110
epoch 181/600,training loss:0.629526,validation loss:0.631197
epoch 182/600,training loss:0.629449,validation loss:0.630940
epoch 183/600,training loss:0.629366,validation loss:0.630866
epoch 184/600,training loss:0.629410,validation loss:0.630673
epoch 185/600,training loss:0.629221,validation loss:0.630839
epoch 186/600,training loss:0.629351,validation loss:0.630748
epoch 187/600,training loss:0.629195,validation loss:0.630892
epoch 188/600,training loss:0.629112,validation loss:0.630737
epoch 189/600,training loss:0.629095,validation loss:0.630696
epoch 190/600,training loss:0.629018,validation loss:0.630768
epoch 191/600,training loss:0.629001,validation loss:0.630452
epoch 192/600,training loss:0.629045,validation loss:0.630364
epoch 193/600,training loss:0.628882,validation loss:0.630651
epoch 194/600,training loss:0.628923,validation loss:0.630605
epoch 195/600,training loss:0.628924,validation loss:0.630293
epoch 196/600,training loss:0.628865,validation loss:0.630538
epoch 197/600,training loss:0.628703,validation loss:0.630550
epoch 198/600,training loss:0.628725,validation loss:0.630620
epoch 199/600,training loss:0.628583,validation loss:0.630263
epoch 200/600,training loss:0.628749,validation loss:0.630465
epoch 201/600,training loss:0.628634,validation loss:0.630462
epoch 202/600,training loss:0.628761,validation loss:0.630358
epoch 203/600,training loss:0.628491,validation loss:0.630317
epoch 204/600,training loss:0.628506,validation loss:0.630265
epoch 205/600,training loss:0.628379,validation loss:0.630088
epoch 206/600,training loss:0.628306,validation loss:0.629992
epoch 207/600,training loss:0.628304,validation loss:0.630084
epoch 208/600,training loss:0.628132,validation loss:0.630162
epoch 209/600,training loss:0.628080,validation loss:0.629877
epoch 210/600,training loss:0.627971,validation loss:0.630062
epoch 211/600,training loss:0.628302,validation loss:0.630040
epoch 212/600,training loss:0.627908,validation loss:0.629812
epoch 213/600,training loss:0.628267,validation loss:0.629656
epoch 214/600,training loss:0.627810,validation loss:0.629677
epoch 215/600,training loss:0.627884,validation loss:0.629707
epoch 216/600,training loss:0.627918,validation loss:0.629661
epoch 217/600,training loss:0.627729,validation loss:0.629815
epoch 218/600,training loss:0.627820,validation loss:0.629870
epoch 219/600,training loss:0.627742,validation loss:0.629651
epoch 220/600,training loss:0.627619,validation loss:0.629612
epoch 221/600,training loss:0.627812,validation loss:0.629953
epoch 222/600,training loss:0.627759,validation loss:0.629440
epoch 223/600,training loss:0.627580,validation loss:0.629692
epoch 224/600,training loss:0.627704,validation loss:0.629493
epoch 225/600,training loss:0.627586,validation loss:0.629398
epoch 226/600,training loss:0.627674,validation loss:0.629556
epoch 227/600,training loss:0.627367,validation loss:0.629421
epoch 228/600,training loss:0.627452,validation loss:0.629351
epoch 229/600,training loss:0.627293,validation loss:0.629208
epoch 230/600,training loss:0.627282,validation loss:0.629672
epoch 231/600,training loss:0.627381,validation loss:0.629401
epoch 232/600,training loss:0.627226,validation loss:0.629363
epoch 233/600,training loss:0.627291,validation loss:0.629059
epoch 234/600,training loss:0.627268,validation loss:0.629287
epoch 235/600,training loss:0.627239,validation loss:0.629241
epoch 236/600,training loss:0.627030,validation loss:0.629152
epoch 237/600,training loss:0.627037,validation loss:0.629276
epoch 238/600,training loss:0.627170,validation loss:0.629160
epoch 239/600,training loss:0.626984,validation loss:0.629148
epoch 240/600,training loss:0.627070,validation loss:0.629292
epoch 241/600,training loss:0.626949,validation loss:0.629033
epoch 242/600,training loss:0.627002,validation loss:0.629209
epoch 243/600,training loss:0.626945,validation loss:0.629064
epoch 244/600,training loss:0.626841,validation loss:0.629114
epoch 245/600,training loss:0.626752,validation loss:0.628515
epoch 246/600,training loss:0.626968,validation loss:0.629058
epoch 247/600,training loss:0.626770,validation loss:0.629031
epoch 248/600,training loss:0.626703,validation loss:0.629009
epoch 249/600,training loss:0.626730,validation loss:0.629034
epoch 250/600,training loss:0.626568,validation loss:0.628526
epoch 251/600,training loss:0.626576,validation loss:0.628925
epoch 252/600,training loss:0.626700,validation loss:0.628604
epoch 253/600,training loss:0.626516,validation loss:0.628799
epoch 254/600,training loss:0.626269,validation loss:0.628866
epoch 255/600,training loss:0.626482,validation loss:0.628901
epoch 256/600,training loss:0.626364,validation loss:0.628787
epoch 257/600,training loss:0.626458,validation loss:0.628590
epoch 258/600,training loss:0.626365,validation loss:0.628612
epoch 259/600,training loss:0.626323,validation loss:0.628735
epoch 260/600,training loss:0.626210,validation loss:0.628656
epoch 261/600,training loss:0.626490,validation loss:0.628315
epoch 262/600,training loss:0.626295,validation loss:0.628466
epoch 263/600,training loss:0.626138,validation loss:0.628604
epoch 264/600,training loss:0.626273,validation loss:0.628795
epoch 265/600,training loss:0.626142,validation loss:0.628499
epoch 266/600,training loss:0.625927,validation loss:0.628194
epoch 267/600,training loss:0.626016,validation loss:0.628344
epoch 268/600,training loss:0.626021,validation loss:0.628475
epoch 269/600,training loss:0.625842,validation loss:0.628293
epoch 270/600,training loss:0.625946,validation loss:0.628256
epoch 271/600,training loss:0.625632,validation loss:0.628480
epoch 272/600,training loss:0.625814,validation loss:0.628429
epoch 273/600,training loss:0.625850,validation loss:0.628294
epoch 274/600,training loss:0.625819,validation loss:0.628159
epoch 275/600,training loss:0.625847,validation loss:0.628180
epoch 276/600,training loss:0.625656,validation loss:0.628418
epoch 277/600,training loss:0.625764,validation loss:0.628289
epoch 278/600,training loss:0.625548,validation loss:0.628162
epoch 279/600,training loss:0.625675,validation loss:0.627955
epoch 280/600,training loss:0.625538,validation loss:0.627935
epoch 281/600,training loss:0.625629,validation loss:0.628309
epoch 282/600,training loss:0.625528,validation loss:0.628317
epoch 283/600,training loss:0.625415,validation loss:0.628037
epoch 284/600,training loss:0.625355,validation loss:0.628102
epoch 285/600,training loss:0.625415,validation loss:0.627817
epoch 286/600,training loss:0.625416,validation loss:0.628284
epoch 287/600,training loss:0.625293,validation loss:0.628280
epoch 288/600,training loss:0.625194,validation loss:0.627945
epoch 289/600,training loss:0.625393,validation loss:0.627872
epoch 290/600,training loss:0.625249,validation loss:0.627887
epoch 291/600,training loss:0.625117,validation loss:0.627819
epoch 292/600,training loss:0.625282,validation loss:0.628103
epoch 293/600,training loss:0.625379,validation loss:0.628197
epoch 294/600,training loss:0.625190,validation loss:0.628000
epoch 295/600,training loss:0.625101,validation loss:0.628012
epoch 296/600,training loss:0.625094,validation loss:0.628066
epoch 297/600,training loss:0.624990,validation loss:0.627591
epoch 298/600,training loss:0.625162,validation loss:0.627786
epoch 299/600,training loss:0.625120,validation loss:0.627764
epoch 300/600,training loss:0.625112,validation loss:0.627755
epoch 301/600,training loss:0.625052,validation loss:0.627959
epoch 302/600,training loss:0.625062,validation loss:0.627843
epoch 303/600,training loss:0.624899,validation loss:0.627682
epoch 304/600,training loss:0.624895,validation loss:0.627880
epoch 305/600,training loss:0.624745,validation loss:0.627663
epoch 306/600,training loss:0.624864,validation loss:0.627645
epoch 307/600,training loss:0.624883,validation loss:0.627907
epoch 308/600,training loss:0.624777,validation loss:0.627899
epoch 309/600,training loss:0.624765,validation loss:0.627604
epoch 310/600,training loss:0.624604,validation loss:0.627534
epoch 311/600,training loss:0.624604,validation loss:0.627352
epoch 312/600,training loss:0.624504,validation loss:0.627785
epoch 313/600,training loss:0.624674,validation loss:0.627613
epoch 314/600,training loss:0.624390,validation loss:0.627348
epoch 315/600,training loss:0.624598,validation loss:0.627537
epoch 316/600,training loss:0.624483,validation loss:0.627490
epoch 317/600,training loss:0.624523,validation loss:0.627343
epoch 318/600,training loss:0.624415,validation loss:0.627540
epoch 319/600,training loss:0.624408,validation loss:0.627529
epoch 320/600,training loss:0.624316,validation loss:0.627365
epoch 321/600,training loss:0.624331,validation loss:0.627579
epoch 322/600,training loss:0.624347,validation loss:0.627289
epoch 323/600,training loss:0.624207,validation loss:0.627488
epoch 324/600,training loss:0.624188,validation loss:0.627490
epoch 325/600,training loss:0.624331,validation loss:0.627363
epoch 326/600,training loss:0.624161,validation loss:0.627565
epoch 327/600,training loss:0.624062,validation loss:0.627441
epoch 328/600,training loss:0.624299,validation loss:0.627237
epoch 329/600,training loss:0.624022,validation loss:0.627464
epoch 330/600,training loss:0.624181,validation loss:0.627283
epoch 331/600,training loss:0.624198,validation loss:0.627409
epoch 332/600,training loss:0.624058,validation loss:0.627203
epoch 333/600,training loss:0.624124,validation loss:0.627248
epoch 334/600,training loss:0.623946,validation loss:0.627225
epoch 335/600,training loss:0.624136,validation loss:0.627447
epoch 336/600,training loss:0.624064,validation loss:0.627083
epoch 337/600,training loss:0.623961,validation loss:0.627261
epoch 338/600,training loss:0.623862,validation loss:0.627214
epoch 339/600,training loss:0.623948,validation loss:0.627340
epoch 340/600,training loss:0.623929,validation loss:0.627204
epoch 341/600,training loss:0.623853,validation loss:0.627111
epoch 342/600,training loss:0.623906,validation loss:0.627180
epoch 343/600,training loss:0.623765,validation loss:0.627015
epoch 344/600,training loss:0.623847,validation loss:0.626927
epoch 345/600,training loss:0.623862,validation loss:0.626995
epoch 346/600,training loss:0.623824,validation loss:0.627087
epoch 347/600,training loss:0.623783,validation loss:0.626946
epoch 348/600,training loss:0.623861,validation loss:0.626955
epoch 349/600,training loss:0.623790,validation loss:0.627017
epoch 350/600,training loss:0.623752,validation loss:0.627012
epoch 351/600,training loss:0.623519,validation loss:0.626997
epoch 352/600,training loss:0.623469,validation loss:0.627003
epoch 353/600,training loss:0.623695,validation loss:0.626956
epoch 354/600,training loss:0.623365,validation loss:0.626948
epoch 355/600,training loss:0.623526,validation loss:0.627192
epoch 356/600,training loss:0.623287,validation loss:0.627097
epoch 357/600,training loss:0.623403,validation loss:0.627063
epoch 358/600,training loss:0.623386,validation loss:0.626942
epoch 359/600,training loss:0.623580,validation loss:0.627098
epoch 360/600,training loss:0.623328,validation loss:0.626640
epoch 361/600,training loss:0.623381,validation loss:0.626987
epoch 362/600,training loss:0.623298,validation loss:0.626724
epoch 363/600,training loss:0.623189,validation loss:0.626692
epoch 364/600,training loss:0.623150,validation loss:0.627015
epoch 365/600,training loss:0.623025,validation loss:0.626710
epoch 366/600,training loss:0.623232,validation loss:0.626614
epoch 367/600,training loss:0.622956,validation loss:0.626766
epoch 368/600,training loss:0.623082,validation loss:0.626954
epoch 369/600,training loss:0.623047,validation loss:0.626763
epoch 370/600,training loss:0.622947,validation loss:0.626922
epoch 371/600,training loss:0.623098,validation loss:0.626794
epoch 372/600,training loss:0.623028,validation loss:0.627058
epoch 373/600,training loss:0.623257,validation loss:0.626606
epoch 374/600,training loss:0.623069,validation loss:0.626562
epoch 375/600,training loss:0.623105,validation loss:0.626891
epoch 376/600,training loss:0.622911,validation loss:0.626510
epoch 377/600,training loss:0.622824,validation loss:0.626570
epoch 378/600,training loss:0.623022,validation loss:0.626666
epoch 379/600,training loss:0.622981,validation loss:0.626898
epoch 380/600,training loss:0.622750,validation loss:0.626651
epoch 381/600,training loss:0.622767,validation loss:0.626736
epoch 382/600,training loss:0.622525,validation loss:0.626612
epoch 383/600,training loss:0.622839,validation loss:0.626832
epoch 384/600,training loss:0.622896,validation loss:0.626548
epoch 385/600,training loss:0.622645,validation loss:0.626744
epoch 386/600,training loss:0.622729,validation loss:0.626904
epoch 387/600,training loss:0.622772,validation loss:0.626548
epoch 388/600,training loss:0.622775,validation loss:0.626791
epoch 389/600,training loss:0.622597,validation loss:0.626668
epoch 390/600,training loss:0.622556,validation loss:0.626485
epoch 391/600,training loss:0.622785,validation loss:0.626447
epoch 392/600,training loss:0.622668,validation loss:0.626476
epoch 393/600,training loss:0.622457,validation loss:0.626720
epoch 394/600,training loss:0.622547,validation loss:0.626654
epoch 395/600,training loss:0.622468,validation loss:0.626706
epoch 396/600,training loss:0.622428,validation loss:0.626425
epoch 397/600,training loss:0.622610,validation loss:0.626356
epoch 398/600,training loss:0.622540,validation loss:0.626469
epoch 399/600,training loss:0.622546,validation loss:0.626376
epoch 400/600,training loss:0.622365,validation loss:0.626605
epoch 401/600,training loss:0.622539,validation loss:0.626566
epoch 402/600,training loss:0.622412,validation loss:0.626335
epoch 403/600,training loss:0.622249,validation loss:0.626612
epoch 404/600,training loss:0.622392,validation loss:0.626387
epoch 405/600,training loss:0.622396,validation loss:0.626537
epoch 406/600,training loss:0.622256,validation loss:0.626230
epoch 407/600,training loss:0.622252,validation loss:0.626215
epoch 408/600,training loss:0.622228,validation loss:0.626529
epoch 409/600,training loss:0.622120,validation loss:0.626403
epoch 410/600,training loss:0.622285,validation loss:0.626285
epoch 411/600,training loss:0.622165,validation loss:0.626455
epoch 412/600,training loss:0.622176,validation loss:0.626597
epoch 413/600,training loss:0.622027,validation loss:0.626217
epoch 414/600,training loss:0.622086,validation loss:0.626608
epoch 415/600,training loss:0.621966,validation loss:0.626504
epoch 416/600,training loss:0.622000,validation loss:0.626402
epoch 417/600,training loss:0.621897,validation loss:0.626170
epoch 418/600,training loss:0.621956,validation loss:0.626186
epoch 419/600,training loss:0.622031,validation loss:0.626303
epoch 420/600,training loss:0.621958,validation loss:0.626296
epoch 421/600,training loss:0.621821,validation loss:0.626407
epoch 422/600,training loss:0.622112,validation loss:0.626313
epoch 423/600,training loss:0.621944,validation loss:0.626352
epoch 424/600,training loss:0.622000,validation loss:0.626213
epoch 425/600,training loss:0.621760,validation loss:0.626193
epoch 426/600,training loss:0.621875,validation loss:0.626134
epoch 427/600,training loss:0.621823,validation loss:0.626264
epoch 428/600,training loss:0.621774,validation loss:0.626314
epoch 429/600,training loss:0.621785,validation loss:0.626162
epoch 430/600,training loss:0.621659,validation loss:0.626133
epoch 431/600,training loss:0.621693,validation loss:0.626252
epoch 432/600,training loss:0.621666,validation loss:0.626305
epoch 433/600,training loss:0.621610,validation loss:0.625925
epoch 434/600,training loss:0.621711,validation loss:0.626245
epoch 435/600,training loss:0.621607,validation loss:0.626097
epoch 436/600,training loss:0.621655,validation loss:0.626049
epoch 437/600,training loss:0.621789,validation loss:0.625927
epoch 438/600,training loss:0.621528,validation loss:0.626188
epoch 439/600,training loss:0.621550,validation loss:0.626257
epoch 440/600,training loss:0.621617,validation loss:0.625912
epoch 441/600,training loss:0.621552,validation loss:0.626041
epoch 442/600,training loss:0.621508,validation loss:0.626062
epoch 443/600,training loss:0.621319,validation loss:0.625997
epoch 444/600,training loss:0.621309,validation loss:0.625866
epoch 445/600,training loss:0.621462,validation loss:0.626232
epoch 446/600,training loss:0.621476,validation loss:0.625868
epoch 447/600,training loss:0.621285,validation loss:0.626206
epoch 448/600,training loss:0.621463,validation loss:0.626018
epoch 449/600,training loss:0.621273,validation loss:0.625978
epoch 450/600,training loss:0.621442,validation loss:0.626123
epoch 451/600,training loss:0.621318,validation loss:0.626110
epoch 452/600,training loss:0.621221,validation loss:0.626018
epoch 453/600,training loss:0.621347,validation loss:0.625928
epoch 454/600,training loss:0.621396,validation loss:0.625800
epoch 455/600,training loss:0.621296,validation loss:0.626226
epoch 456/600,training loss:0.621196,validation loss:0.625960
epoch 457/600,training loss:0.621241,validation loss:0.626224
epoch 458/600,training loss:0.621160,validation loss:0.625647
epoch 459/600,training loss:0.621145,validation loss:0.625934
epoch 460/600,training loss:0.621278,validation loss:0.626025
epoch 461/600,training loss:0.621156,validation loss:0.626107
epoch 462/600,training loss:0.621029,validation loss:0.625852
epoch 463/600,training loss:0.621284,validation loss:0.625889
epoch 464/600,training loss:0.621035,validation loss:0.625823
epoch 465/600,training loss:0.621283,validation loss:0.625909
epoch 466/600,training loss:0.621112,validation loss:0.626275
epoch 467/600,training loss:0.621066,validation loss:0.626013
epoch 468/600,training loss:0.621270,validation loss:0.626086
epoch 469/600,training loss:0.621183,validation loss:0.625893
epoch 470/600,training loss:0.621030,validation loss:0.625991
epoch 471/600,training loss:0.620993,validation loss:0.625931
epoch 472/600,training loss:0.620961,validation loss:0.625954
epoch 473/600,training loss:0.620953,validation loss:0.625797
epoch 474/600,training loss:0.621055,validation loss:0.625983
epoch 475/600,training loss:0.620650,validation loss:0.625969
epoch 476/600,training loss:0.620874,validation loss:0.625787
epoch 477/600,training loss:0.620974,validation loss:0.625905
epoch 478/600,training loss:0.620909,validation loss:0.625861
epoch 479/600,training loss:0.620876,validation loss:0.625631
epoch 480/600,training loss:0.620951,validation loss:0.625721
epoch 481/600,training loss:0.620910,validation loss:0.625792
epoch 482/600,training loss:0.620872,validation loss:0.626084
epoch 483/600,training loss:0.620796,validation loss:0.625954
epoch 484/600,training loss:0.620935,validation loss:0.626012
epoch 485/600,training loss:0.620610,validation loss:0.625871
epoch 486/600,training loss:0.620786,validation loss:0.625646
epoch 487/600,training loss:0.620750,validation loss:0.625865
epoch 488/600,training loss:0.620611,validation loss:0.625872
epoch 489/600,training loss:0.620977,validation loss:0.625616
epoch 490/600,training loss:0.620764,validation loss:0.625778
epoch 491/600,training loss:0.620734,validation loss:0.626119
epoch 492/600,training loss:0.620707,validation loss:0.625802
epoch 493/600,training loss:0.620695,validation loss:0.625812
epoch 494/600,training loss:0.620684,validation loss:0.626003
epoch 495/600,training loss:0.620571,validation loss:0.625677
epoch 496/600,training loss:0.620316,validation loss:0.625712
epoch 497/600,training loss:0.620307,validation loss:0.625548
epoch 498/600,training loss:0.620521,validation loss:0.625648
epoch 499/600,training loss:0.620438,validation loss:0.625740
epoch 500/600,training loss:0.620490,validation loss:0.625464
epoch 501/600,training loss:0.620423,validation loss:0.625794
epoch 502/600,training loss:0.620606,validation loss:0.625775
epoch 503/600,training loss:0.620588,validation loss:0.625821
epoch 504/600,training loss:0.620317,validation loss:0.625893
epoch 505/600,training loss:0.620288,validation loss:0.625661
epoch 506/600,training loss:0.620538,validation loss:0.625400
epoch 507/600,training loss:0.620327,validation loss:0.625626
epoch 508/600,training loss:0.620396,validation loss:0.625893
epoch 509/600,training loss:0.620368,validation loss:0.625616
epoch 510/600,training loss:0.620269,validation loss:0.625665
epoch 511/600,training loss:0.620344,validation loss:0.625713
epoch 512/600,training loss:0.620215,validation loss:0.625890
epoch 513/600,training loss:0.620401,validation loss:0.625516
epoch 514/600,training loss:0.620148,validation loss:0.625808
epoch 515/600,training loss:0.620274,validation loss:0.625740
epoch 516/600,training loss:0.620174,validation loss:0.625810
epoch 517/600,training loss:0.620107,validation loss:0.625531
epoch 518/600,training loss:0.620137,validation loss:0.625304
epoch 519/600,training loss:0.620250,validation loss:0.625610
epoch 520/600,training loss:0.620015,validation loss:0.625501
epoch 521/600,training loss:0.620250,validation loss:0.625620
epoch 522/600,training loss:0.620133,validation loss:0.625279
epoch 523/600,training loss:0.620294,validation loss:0.625489
epoch 524/600,training loss:0.620009,validation loss:0.625528
epoch 525/600,training loss:0.620209,validation loss:0.625375
epoch 526/600,training loss:0.620136,validation loss:0.625878
epoch 527/600,training loss:0.619997,validation loss:0.625633
epoch 528/600,training loss:0.619940,validation loss:0.625375
epoch 529/600,training loss:0.619949,validation loss:0.625761
epoch 530/600,training loss:0.619820,validation loss:0.625301
epoch 531/600,training loss:0.619918,validation loss:0.625762
epoch 532/600,training loss:0.619935,validation loss:0.625617
epoch 533/600,training loss:0.619954,validation loss:0.625663
epoch 534/600,training loss:0.620092,validation loss:0.625541
epoch 535/600,training loss:0.619801,validation loss:0.625438
epoch 536/600,training loss:0.619783,validation loss:0.625315
epoch 537/600,training loss:0.620061,validation loss:0.625722
epoch 538/600,training loss:0.619732,validation loss:0.625659
epoch 539/600,training loss:0.619848,validation loss:0.625898
epoch 540/600,training loss:0.619868,validation loss:0.625630
epoch 541/600,training loss:0.619741,validation loss:0.625438
epoch 542/600,training loss:0.619795,validation loss:0.625582
epoch 543/600,training loss:0.619750,validation loss:0.625618
epoch 544/600,training loss:0.619816,validation loss:0.625491
epoch 545/600,training loss:0.619664,validation loss:0.625733
epoch 546/600,training loss:0.619718,validation loss:0.625900
epoch 547/600,training loss:0.619566,validation loss:0.625383
epoch 548/600,training loss:0.619786,validation loss:0.625632
epoch 549/600,training loss:0.619697,validation loss:0.625290
epoch 550/600,training loss:0.619914,validation loss:0.625482
epoch 551/600,training loss:0.619518,validation loss:0.625472
epoch 552/600,training loss:0.619735,validation loss:0.625417
epoch 553/600,training loss:0.619788,validation loss:0.625726
epoch 554/600,training loss:0.619672,validation loss:0.625557
epoch 555/600,training loss:0.619730,validation loss:0.625378
epoch 556/600,training loss:0.619645,validation loss:0.625383
epoch 557/600,training loss:0.619629,validation loss:0.625505
epoch 558/600,training loss:0.619482,validation loss:0.625567
epoch 559/600,training loss:0.619589,validation loss:0.625513
epoch 560/600,training loss:0.619611,validation loss:0.625642
epoch 561/600,training loss:0.619717,validation loss:0.625579
epoch 562/600,training loss:0.619615,validation loss:0.625471
epoch 563/600,training loss:0.619412,validation loss:0.625770
epoch 564/600,training loss:0.619395,validation loss:0.625514
epoch 565/600,training loss:0.619318,validation loss:0.625448
epoch 566/600,training loss:0.619242,validation loss:0.625277
epoch 567/600,training loss:0.619295,validation loss:0.625306
epoch 568/600,training loss:0.619417,validation loss:0.625341
epoch 569/600,training loss:0.619437,validation loss:0.625585
epoch 570/600,training loss:0.619274,validation loss:0.625495
epoch 571/600,training loss:0.619589,validation loss:0.625156
epoch 572/600,training loss:0.619389,validation loss:0.625596
epoch 573/600,training loss:0.619332,validation loss:0.625072
epoch 574/600,training loss:0.619421,validation loss:0.625330
epoch 575/600,training loss:0.619405,validation loss:0.625019
epoch 576/600,training loss:0.619230,validation loss:0.625441
epoch 577/600,training loss:0.618954,validation loss:0.625639
epoch 578/600,training loss:0.619274,validation loss:0.625592
epoch 579/600,training loss:0.619381,validation loss:0.625358
epoch 580/600,training loss:0.618981,validation loss:0.625340
epoch 581/600,training loss:0.619085,validation loss:0.625579
epoch 582/600,training loss:0.619236,validation loss:0.625409
epoch 583/600,training loss:0.619386,validation loss:0.625370
epoch 584/600,training loss:0.619229,validation loss:0.625552
epoch 585/600,training loss:0.619004,validation loss:0.625353
epoch 586/600,training loss:0.619131,validation loss:0.625520
epoch 587/600,training loss:0.619055,validation loss:0.625210
epoch 588/600,training loss:0.619215,validation loss:0.625301
epoch 589/600,training loss:0.618965,validation loss:0.625319
epoch 590/600,training loss:0.619168,validation loss:0.625386
epoch 591/600,training loss:0.619047,validation loss:0.625380
epoch 592/600,training loss:0.618989,validation loss:0.625132
epoch 593/600,training loss:0.619044,validation loss:0.625312
epoch 594/600,training loss:0.618994,validation loss:0.625653
epoch 595/600,training loss:0.619037,validation loss:0.625264
epoch 596/600,training loss:0.619094,validation loss:0.625144
epoch 597/600,training loss:0.618866,validation loss:0.625138
epoch 598/600,training loss:0.618987,validation loss:0.625299
epoch 599/600,training loss:0.618857,validation loss:0.625309
Finished. Saving the model to /h/172/shawnlyu/projects/machine_learning/CSC2515Dota2DraftPredictionProject/algorithms/shawn/exp/fc_4.batch.pth
The best validation accuracy occurs at 0th epoch