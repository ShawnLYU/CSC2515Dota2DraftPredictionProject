epoch 0/600,training loss:0.691145,validation loss:0.689598
epoch 1/600,training loss:0.689139,validation loss:0.688863
epoch 2/600,training loss:0.688336,validation loss:0.687980
epoch 3/600,training loss:0.687328,validation loss:0.686791
epoch 4/600,training loss:0.685885,validation loss:0.685045
epoch 5/600,training loss:0.683718,validation loss:0.682359
epoch 6/600,training loss:0.680329,validation loss:0.678135
epoch 7/600,training loss:0.675098,validation loss:0.671734
epoch 8/600,training loss:0.667527,validation loss:0.662982
epoch 9/600,training loss:0.658106,validation loss:0.653278
epoch 10/600,training loss:0.649089,validation loss:0.645257
epoch 11/600,training loss:0.642449,validation loss:0.640008
epoch 12/600,training loss:0.638279,validation loss:0.636766
epoch 13/600,training loss:0.635712,validation loss:0.634729
epoch 14/600,training loss:0.634008,validation loss:0.633403
epoch 15/600,training loss:0.632937,validation loss:0.632484
epoch 16/600,training loss:0.632189,validation loss:0.631917
epoch 17/600,training loss:0.631653,validation loss:0.631443
epoch 18/600,training loss:0.631282,validation loss:0.631127
epoch 19/600,training loss:0.630994,validation loss:0.630898
epoch 20/600,training loss:0.630791,validation loss:0.630734
epoch 21/600,training loss:0.630603,validation loss:0.630601
epoch 22/600,training loss:0.630511,validation loss:0.630523
epoch 23/600,training loss:0.630368,validation loss:0.630402
epoch 24/600,training loss:0.630299,validation loss:0.630334
epoch 25/600,training loss:0.630185,validation loss:0.630270
epoch 26/600,training loss:0.630169,validation loss:0.630228
epoch 27/600,training loss:0.630072,validation loss:0.630173
epoch 28/600,training loss:0.630030,validation loss:0.630127
epoch 29/600,training loss:0.629952,validation loss:0.630096
epoch 30/600,training loss:0.629923,validation loss:0.630050
epoch 31/600,training loss:0.629861,validation loss:0.630019
epoch 32/600,training loss:0.629847,validation loss:0.629978
epoch 33/600,training loss:0.629796,validation loss:0.629952
epoch 34/600,training loss:0.629699,validation loss:0.629921
epoch 35/600,training loss:0.629703,validation loss:0.629878
epoch 36/600,training loss:0.629665,validation loss:0.629849
epoch 37/600,training loss:0.629608,validation loss:0.629831
epoch 38/600,training loss:0.629599,validation loss:0.629790
epoch 39/600,training loss:0.629536,validation loss:0.629757
epoch 40/600,training loss:0.629517,validation loss:0.629730
epoch 41/600,training loss:0.629468,validation loss:0.629698
epoch 42/600,training loss:0.629375,validation loss:0.629665
epoch 43/600,training loss:0.629369,validation loss:0.629641
epoch 44/600,training loss:0.629338,validation loss:0.629607
epoch 45/600,training loss:0.629292,validation loss:0.629568
epoch 46/600,training loss:0.629256,validation loss:0.629533
epoch 47/600,training loss:0.629191,validation loss:0.629497
epoch 48/600,training loss:0.629128,validation loss:0.629469
epoch 49/600,training loss:0.629114,validation loss:0.629442
epoch 50/600,training loss:0.629077,validation loss:0.629400
epoch 51/600,training loss:0.628980,validation loss:0.629368
epoch 52/600,training loss:0.628984,validation loss:0.629322
epoch 53/600,training loss:0.628927,validation loss:0.629284
epoch 54/600,training loss:0.628884,validation loss:0.629240
epoch 55/600,training loss:0.628831,validation loss:0.629204
epoch 56/600,training loss:0.628767,validation loss:0.629159
epoch 57/600,training loss:0.628739,validation loss:0.629121
epoch 58/600,training loss:0.628657,validation loss:0.629082
epoch 59/600,training loss:0.628625,validation loss:0.629039
epoch 60/600,training loss:0.628548,validation loss:0.628993
epoch 61/600,training loss:0.628486,validation loss:0.628944
epoch 62/600,training loss:0.628424,validation loss:0.628899
epoch 63/600,training loss:0.628376,validation loss:0.628861
epoch 64/600,training loss:0.628326,validation loss:0.628801
epoch 65/600,training loss:0.628218,validation loss:0.628749
epoch 66/600,training loss:0.628184,validation loss:0.628707
epoch 67/600,training loss:0.628138,validation loss:0.628646
epoch 68/600,training loss:0.628093,validation loss:0.628593
epoch 69/600,training loss:0.628004,validation loss:0.628548
epoch 70/600,training loss:0.627936,validation loss:0.628489
epoch 71/600,training loss:0.627835,validation loss:0.628434
epoch 72/600,training loss:0.627807,validation loss:0.628369
epoch 73/600,training loss:0.627707,validation loss:0.628308
epoch 74/600,training loss:0.627648,validation loss:0.628288
epoch 75/600,training loss:0.627588,validation loss:0.628190
epoch 76/600,training loss:0.627501,validation loss:0.628142
epoch 77/600,training loss:0.627404,validation loss:0.628068
epoch 78/600,training loss:0.627349,validation loss:0.628004
epoch 79/600,training loss:0.627249,validation loss:0.627933
epoch 80/600,training loss:0.627180,validation loss:0.627878
epoch 81/600,training loss:0.627088,validation loss:0.627799
epoch 82/600,training loss:0.626998,validation loss:0.627724
epoch 83/600,training loss:0.626954,validation loss:0.627654
epoch 84/600,training loss:0.626835,validation loss:0.627591
epoch 85/600,training loss:0.626730,validation loss:0.627513
epoch 86/600,training loss:0.626634,validation loss:0.627432
epoch 87/600,training loss:0.626560,validation loss:0.627392
epoch 88/600,training loss:0.626482,validation loss:0.627278
epoch 89/600,training loss:0.626334,validation loss:0.627194
epoch 90/600,training loss:0.626251,validation loss:0.627119
epoch 91/600,training loss:0.626175,validation loss:0.627028
epoch 92/600,training loss:0.626036,validation loss:0.626944
epoch 93/600,training loss:0.625919,validation loss:0.626861
epoch 94/600,training loss:0.625816,validation loss:0.626775
epoch 95/600,training loss:0.625701,validation loss:0.626696
epoch 96/600,training loss:0.625578,validation loss:0.626591
epoch 97/600,training loss:0.625501,validation loss:0.626523
epoch 98/600,training loss:0.625386,validation loss:0.626424
epoch 99/600,training loss:0.625273,validation loss:0.626319
epoch 100/600,training loss:0.625138,validation loss:0.626223
epoch 101/600,training loss:0.625053,validation loss:0.626142
epoch 102/600,training loss:0.624896,validation loss:0.626027
epoch 103/600,training loss:0.624751,validation loss:0.625962
epoch 104/600,training loss:0.624645,validation loss:0.625833
epoch 105/600,training loss:0.624521,validation loss:0.625737
epoch 106/600,training loss:0.624386,validation loss:0.625639
epoch 107/600,training loss:0.624290,validation loss:0.625530
epoch 108/600,training loss:0.624135,validation loss:0.625448
epoch 109/600,training loss:0.624003,validation loss:0.625329
epoch 110/600,training loss:0.623849,validation loss:0.625238
epoch 111/600,training loss:0.623728,validation loss:0.625109
epoch 112/600,training loss:0.623594,validation loss:0.625002
epoch 113/600,training loss:0.623454,validation loss:0.624906
epoch 114/600,training loss:0.623290,validation loss:0.624804
epoch 115/600,training loss:0.623162,validation loss:0.624715
epoch 116/600,training loss:0.623036,validation loss:0.624586
epoch 117/600,training loss:0.622892,validation loss:0.624480
epoch 118/600,training loss:0.622704,validation loss:0.624375
epoch 119/600,training loss:0.622624,validation loss:0.624257
epoch 120/600,training loss:0.622447,validation loss:0.624163
epoch 121/600,training loss:0.622313,validation loss:0.624046
epoch 122/600,training loss:0.622184,validation loss:0.623942
epoch 123/600,training loss:0.622037,validation loss:0.623835
epoch 124/600,training loss:0.621871,validation loss:0.623740
epoch 125/600,training loss:0.621724,validation loss:0.623625
epoch 126/600,training loss:0.621583,validation loss:0.623528
epoch 127/600,training loss:0.621428,validation loss:0.623404
epoch 128/600,training loss:0.621292,validation loss:0.623299
epoch 129/600,training loss:0.621141,validation loss:0.623191
epoch 130/600,training loss:0.620986,validation loss:0.623115
epoch 131/600,training loss:0.620833,validation loss:0.622984
epoch 132/600,training loss:0.620676,validation loss:0.622881
epoch 133/600,training loss:0.620527,validation loss:0.622789
epoch 134/600,training loss:0.620429,validation loss:0.622677
epoch 135/600,training loss:0.620267,validation loss:0.622581
epoch 136/600,training loss:0.620102,validation loss:0.622484
epoch 137/600,training loss:0.619944,validation loss:0.622378
epoch 138/600,training loss:0.619822,validation loss:0.622271
epoch 139/600,training loss:0.619708,validation loss:0.622184
epoch 140/600,training loss:0.619522,validation loss:0.622133
epoch 141/600,training loss:0.619394,validation loss:0.621987
epoch 142/600,training loss:0.619214,validation loss:0.621902
epoch 143/600,training loss:0.619053,validation loss:0.621809
epoch 144/600,training loss:0.618953,validation loss:0.621731
epoch 145/600,training loss:0.618782,validation loss:0.621613
epoch 146/600,training loss:0.618642,validation loss:0.621543
epoch 147/600,training loss:0.618487,validation loss:0.621432
epoch 148/600,training loss:0.618363,validation loss:0.621349
epoch 149/600,training loss:0.618201,validation loss:0.621271
epoch 150/600,training loss:0.618086,validation loss:0.621204
epoch 151/600,training loss:0.617960,validation loss:0.621115
epoch 152/600,training loss:0.617841,validation loss:0.621005
epoch 153/600,training loss:0.617671,validation loss:0.620947
epoch 154/600,training loss:0.617544,validation loss:0.620832
epoch 155/600,training loss:0.617408,validation loss:0.620805
epoch 156/600,training loss:0.617286,validation loss:0.620694
epoch 157/600,training loss:0.617127,validation loss:0.620605
epoch 158/600,training loss:0.616977,validation loss:0.620537
epoch 159/600,training loss:0.616898,validation loss:0.620490
epoch 160/600,training loss:0.616776,validation loss:0.620386
epoch 161/600,training loss:0.616633,validation loss:0.620323
epoch 162/600,training loss:0.616490,validation loss:0.620308
epoch 163/600,training loss:0.616391,validation loss:0.620177
epoch 164/600,training loss:0.616278,validation loss:0.620132
epoch 165/600,training loss:0.616091,validation loss:0.620081
epoch 166/600,training loss:0.616029,validation loss:0.620013
epoch 167/600,training loss:0.615869,validation loss:0.619945
epoch 168/600,training loss:0.615744,validation loss:0.619885
epoch 169/600,training loss:0.615604,validation loss:0.619785
epoch 170/600,training loss:0.615488,validation loss:0.619796
epoch 171/600,training loss:0.615406,validation loss:0.619728
epoch 172/600,training loss:0.615271,validation loss:0.619686
epoch 173/600,training loss:0.615152,validation loss:0.619563
epoch 174/600,training loss:0.615086,validation loss:0.619532
epoch 175/600,training loss:0.614903,validation loss:0.619471
epoch 176/600,training loss:0.614775,validation loss:0.619473
epoch 177/600,training loss:0.614694,validation loss:0.619365
epoch 178/600,training loss:0.614576,validation loss:0.619313
epoch 179/600,training loss:0.614444,validation loss:0.619277
epoch 180/600,training loss:0.614384,validation loss:0.619199
epoch 181/600,training loss:0.614225,validation loss:0.619182
epoch 182/600,training loss:0.614115,validation loss:0.619140
epoch 183/600,training loss:0.613991,validation loss:0.619064
epoch 184/600,training loss:0.613923,validation loss:0.619035
epoch 185/600,training loss:0.613800,validation loss:0.618988
epoch 186/600,training loss:0.613706,validation loss:0.618929
epoch 187/600,training loss:0.613592,validation loss:0.618910
epoch 188/600,training loss:0.613475,validation loss:0.618852
epoch 189/600,training loss:0.613398,validation loss:0.618844
epoch 190/600,training loss:0.613269,validation loss:0.618779
epoch 191/600,training loss:0.613219,validation loss:0.618738
epoch 192/600,training loss:0.613081,validation loss:0.618729
epoch 193/600,training loss:0.613034,validation loss:0.618648
epoch 194/600,training loss:0.612908,validation loss:0.618617
epoch 195/600,training loss:0.612792,validation loss:0.618598
epoch 196/600,training loss:0.612733,validation loss:0.618557
epoch 197/600,training loss:0.612581,validation loss:0.618552
epoch 198/600,training loss:0.612493,validation loss:0.618511
epoch 199/600,training loss:0.612401,validation loss:0.618532
epoch 200/600,training loss:0.612310,validation loss:0.618460
epoch 201/600,training loss:0.612242,validation loss:0.618394
epoch 202/600,training loss:0.612150,validation loss:0.618373
epoch 203/600,training loss:0.612046,validation loss:0.618340
epoch 204/600,training loss:0.611953,validation loss:0.618328
epoch 205/600,training loss:0.611865,validation loss:0.618290
epoch 206/600,training loss:0.611811,validation loss:0.618363
epoch 207/600,training loss:0.611676,validation loss:0.618278
epoch 208/600,training loss:0.611628,validation loss:0.618221
epoch 209/600,training loss:0.611514,validation loss:0.618237
epoch 210/600,training loss:0.611411,validation loss:0.618160
epoch 211/600,training loss:0.611397,validation loss:0.618174
epoch 212/600,training loss:0.611230,validation loss:0.618128
epoch 213/600,training loss:0.611178,validation loss:0.618208
epoch 214/600,training loss:0.611094,validation loss:0.618067
epoch 215/600,training loss:0.611034,validation loss:0.618066
epoch 216/600,training loss:0.610920,validation loss:0.618069
epoch 217/600,training loss:0.610842,validation loss:0.618008
epoch 218/600,training loss:0.610772,validation loss:0.618019
epoch 219/600,training loss:0.610677,validation loss:0.618034
epoch 220/600,training loss:0.610582,validation loss:0.617926
epoch 221/600,training loss:0.610537,validation loss:0.617928
epoch 222/600,training loss:0.610428,validation loss:0.617918
epoch 223/600,training loss:0.610318,validation loss:0.617895
epoch 224/600,training loss:0.610217,validation loss:0.617885
epoch 225/600,training loss:0.610110,validation loss:0.617848
epoch 226/600,training loss:0.610117,validation loss:0.617828
epoch 227/600,training loss:0.610049,validation loss:0.617844
epoch 228/600,training loss:0.609951,validation loss:0.617798
epoch 229/600,training loss:0.609850,validation loss:0.617784
epoch 230/600,training loss:0.609806,validation loss:0.617880
epoch 231/600,training loss:0.609744,validation loss:0.617766
epoch 232/600,training loss:0.609623,validation loss:0.617842
epoch 233/600,training loss:0.609560,validation loss:0.617733
epoch 234/600,training loss:0.609524,validation loss:0.617773
epoch 235/600,training loss:0.609394,validation loss:0.617737
epoch 236/600,training loss:0.609350,validation loss:0.617724
epoch 237/600,training loss:0.609270,validation loss:0.617700
epoch 238/600,training loss:0.609193,validation loss:0.617701
epoch 239/600,training loss:0.609117,validation loss:0.617694
epoch 240/600,training loss:0.609048,validation loss:0.617725
epoch 241/600,training loss:0.609007,validation loss:0.617667
epoch 242/600,training loss:0.608916,validation loss:0.617692
epoch 243/600,training loss:0.608801,validation loss:0.617733
epoch 244/600,training loss:0.608777,validation loss:0.617687
epoch 245/600,training loss:0.608751,validation loss:0.617655
epoch 246/600,training loss:0.608637,validation loss:0.617628
epoch 247/600,training loss:0.608563,validation loss:0.617614
epoch 248/600,training loss:0.608496,validation loss:0.617584
epoch 249/600,training loss:0.608418,validation loss:0.617685
epoch 250/600,training loss:0.608375,validation loss:0.617640
epoch 251/600,training loss:0.608312,validation loss:0.617592
epoch 252/600,training loss:0.608252,validation loss:0.617591
epoch 253/600,training loss:0.608184,validation loss:0.617554
epoch 254/600,training loss:0.608120,validation loss:0.617619
epoch 255/600,training loss:0.608059,validation loss:0.617812
epoch 256/600,training loss:0.607970,validation loss:0.617595
epoch 257/600,training loss:0.607910,validation loss:0.617633
epoch 258/600,training loss:0.607869,validation loss:0.617551
epoch 259/600,training loss:0.607749,validation loss:0.617560
epoch 260/600,training loss:0.607734,validation loss:0.617571
epoch 261/600,training loss:0.607633,validation loss:0.617545
epoch 262/600,training loss:0.607616,validation loss:0.617623
epoch 263/600,training loss:0.607538,validation loss:0.617584
epoch 264/600,training loss:0.607480,validation loss:0.617549
epoch 265/600,training loss:0.607436,validation loss:0.617593
epoch 266/600,training loss:0.607314,validation loss:0.617554
epoch 267/600,training loss:0.607244,validation loss:0.617563
epoch 268/600,training loss:0.607267,validation loss:0.617621
epoch 269/600,training loss:0.607181,validation loss:0.617534
epoch 270/600,training loss:0.607133,validation loss:0.617538
epoch 271/600,training loss:0.607050,validation loss:0.617525
epoch 272/600,training loss:0.607021,validation loss:0.617539
epoch 273/600,training loss:0.606946,validation loss:0.617563
epoch 274/600,training loss:0.606899,validation loss:0.617595
epoch 275/600,training loss:0.606842,validation loss:0.617522
epoch 276/600,training loss:0.606770,validation loss:0.617562
epoch 277/600,training loss:0.606704,validation loss:0.617574
epoch 278/600,training loss:0.606674,validation loss:0.617530
epoch 279/600,training loss:0.606615,validation loss:0.617561
epoch 280/600,training loss:0.606560,validation loss:0.617558
epoch 281/600,training loss:0.606496,validation loss:0.617544
epoch 282/600,training loss:0.606450,validation loss:0.617546
epoch 283/600,training loss:0.606343,validation loss:0.617575
epoch 284/600,training loss:0.606330,validation loss:0.617564
epoch 285/600,training loss:0.606291,validation loss:0.617565
epoch 286/600,training loss:0.606204,validation loss:0.617580
epoch 287/600,training loss:0.606160,validation loss:0.617541
epoch 288/600,training loss:0.606083,validation loss:0.617583
epoch 289/600,training loss:0.606034,validation loss:0.617658
epoch 290/600,training loss:0.606009,validation loss:0.617593
epoch 291/600,training loss:0.605952,validation loss:0.617584
epoch 292/600,training loss:0.605917,validation loss:0.617637
epoch 293/600,training loss:0.605838,validation loss:0.617603
epoch 294/600,training loss:0.605764,validation loss:0.617639
epoch 295/600,training loss:0.605756,validation loss:0.617605
epoch 296/600,training loss:0.605744,validation loss:0.617618
epoch 297/600,training loss:0.605678,validation loss:0.617623
epoch 298/600,training loss:0.605591,validation loss:0.617677
epoch 299/600,training loss:0.605564,validation loss:0.617650
epoch 300/600,training loss:0.605503,validation loss:0.617699
epoch 301/600,training loss:0.605458,validation loss:0.617627
epoch 302/600,training loss:0.605397,validation loss:0.617735
epoch 303/600,training loss:0.605361,validation loss:0.617703
epoch 304/600,training loss:0.605277,validation loss:0.617655
epoch 305/600,training loss:0.605275,validation loss:0.617617
epoch 306/600,training loss:0.605180,validation loss:0.617678
epoch 307/600,training loss:0.605145,validation loss:0.617746
epoch 308/600,training loss:0.605143,validation loss:0.617667
epoch 309/600,training loss:0.605058,validation loss:0.617732
epoch 310/600,training loss:0.605016,validation loss:0.617677
epoch 311/600,training loss:0.604956,validation loss:0.617679
epoch 312/600,training loss:0.604917,validation loss:0.617695
epoch 313/600,training loss:0.604828,validation loss:0.617682
epoch 314/600,training loss:0.604804,validation loss:0.617707
epoch 315/600,training loss:0.604750,validation loss:0.617681
epoch 316/600,training loss:0.604771,validation loss:0.617751
epoch 317/600,training loss:0.604687,validation loss:0.617718
epoch 318/600,training loss:0.604618,validation loss:0.617762
epoch 319/600,training loss:0.604599,validation loss:0.617739
epoch 320/600,training loss:0.604522,validation loss:0.617733
epoch 321/600,training loss:0.604469,validation loss:0.617805
epoch 322/600,training loss:0.604465,validation loss:0.617817
epoch 323/600,training loss:0.604409,validation loss:0.617751
epoch 324/600,training loss:0.604401,validation loss:0.617758
epoch 325/600,training loss:0.604306,validation loss:0.617805
epoch 326/600,training loss:0.604268,validation loss:0.617792
epoch 327/600,training loss:0.604217,validation loss:0.617801
epoch 328/600,training loss:0.604185,validation loss:0.617833
epoch 329/600,training loss:0.604160,validation loss:0.617841
epoch 330/600,training loss:0.604079,validation loss:0.617971
epoch 331/600,training loss:0.604069,validation loss:0.617858
epoch 332/600,training loss:0.603980,validation loss:0.617814
epoch 333/600,training loss:0.603962,validation loss:0.617934
epoch 334/600,training loss:0.603917,validation loss:0.617897
epoch 335/600,training loss:0.603886,validation loss:0.617846
epoch 336/600,training loss:0.603838,validation loss:0.617864
epoch 337/600,training loss:0.603772,validation loss:0.617860
epoch 338/600,training loss:0.603730,validation loss:0.617896
epoch 339/600,training loss:0.603717,validation loss:0.617943
epoch 340/600,training loss:0.603659,validation loss:0.617914
epoch 341/600,training loss:0.603643,validation loss:0.617967
epoch 342/600,training loss:0.603589,validation loss:0.617992
epoch 343/600,training loss:0.603523,validation loss:0.617969
epoch 344/600,training loss:0.603488,validation loss:0.618015
epoch 345/600,training loss:0.603483,validation loss:0.618003
epoch 346/600,training loss:0.603393,validation loss:0.618035
epoch 347/600,training loss:0.603391,validation loss:0.618029
epoch 348/600,training loss:0.603353,validation loss:0.618048
epoch 349/600,training loss:0.603364,validation loss:0.618129
epoch 350/600,training loss:0.603233,validation loss:0.618070
epoch 351/600,training loss:0.603196,validation loss:0.618070
epoch 352/600,training loss:0.603199,validation loss:0.618074
epoch 353/600,training loss:0.603180,validation loss:0.618064
epoch 354/600,training loss:0.603085,validation loss:0.618058
epoch 355/600,training loss:0.603052,validation loss:0.618144
epoch 356/600,training loss:0.602984,validation loss:0.618196
epoch 357/600,training loss:0.602966,validation loss:0.618123
epoch 358/600,training loss:0.602962,validation loss:0.618246
epoch 359/600,training loss:0.602914,validation loss:0.618150
epoch 360/600,training loss:0.602855,validation loss:0.618097
epoch 361/600,training loss:0.602806,validation loss:0.618198
epoch 362/600,training loss:0.602786,validation loss:0.618165
epoch 363/600,training loss:0.602730,validation loss:0.618251
epoch 364/600,training loss:0.602704,validation loss:0.618170
epoch 365/600,training loss:0.602677,validation loss:0.618255
epoch 366/600,training loss:0.602583,validation loss:0.618234
epoch 367/600,training loss:0.602562,validation loss:0.618211
epoch 368/600,training loss:0.602535,validation loss:0.618334
epoch 369/600,training loss:0.602508,validation loss:0.618283
epoch 370/600,training loss:0.602459,validation loss:0.618294
epoch 371/600,training loss:0.602447,validation loss:0.618277
epoch 372/600,training loss:0.602401,validation loss:0.618301
epoch 373/600,training loss:0.602372,validation loss:0.618552
epoch 374/600,training loss:0.602396,validation loss:0.618270
epoch 375/600,training loss:0.602292,validation loss:0.618356
epoch 376/600,training loss:0.602269,validation loss:0.618329
epoch 377/600,training loss:0.602250,validation loss:0.618341
epoch 378/600,training loss:0.602162,validation loss:0.618389
epoch 379/600,training loss:0.602170,validation loss:0.618399
epoch 380/600,training loss:0.602113,validation loss:0.618446
epoch 381/600,training loss:0.602068,validation loss:0.618429
epoch 382/600,training loss:0.602059,validation loss:0.618488
epoch 383/600,training loss:0.602033,validation loss:0.618487
epoch 384/600,training loss:0.601984,validation loss:0.618434
epoch 385/600,training loss:0.601954,validation loss:0.618467
epoch 386/600,training loss:0.601906,validation loss:0.618518
epoch 387/600,training loss:0.601849,validation loss:0.618719
epoch 388/600,training loss:0.601832,validation loss:0.618755
epoch 389/600,training loss:0.601760,validation loss:0.618536
epoch 390/600,training loss:0.601766,validation loss:0.618523
epoch 391/600,training loss:0.601733,validation loss:0.618704
epoch 392/600,training loss:0.601693,validation loss:0.618578
epoch 393/600,training loss:0.601639,validation loss:0.618616
epoch 394/600,training loss:0.601627,validation loss:0.618617
epoch 395/600,training loss:0.601562,validation loss:0.618639
epoch 396/600,training loss:0.601505,validation loss:0.618652
epoch 397/600,training loss:0.601589,validation loss:0.618626
epoch 398/600,training loss:0.601462,validation loss:0.618652
epoch 399/600,training loss:0.601450,validation loss:0.618716
epoch 400/600,training loss:0.601415,validation loss:0.618678
epoch 401/600,training loss:0.601357,validation loss:0.618666
epoch 402/600,training loss:0.601328,validation loss:0.618725
epoch 403/600,training loss:0.601247,validation loss:0.618748
epoch 404/600,training loss:0.601252,validation loss:0.618764
epoch 405/600,training loss:0.601236,validation loss:0.618796
epoch 406/600,training loss:0.601181,validation loss:0.618803
epoch 407/600,training loss:0.601150,validation loss:0.618794
epoch 408/600,training loss:0.601135,validation loss:0.618839
epoch 409/600,training loss:0.601096,validation loss:0.618861
epoch 410/600,training loss:0.601038,validation loss:0.618849
epoch 411/600,training loss:0.600984,validation loss:0.618889
epoch 412/600,training loss:0.600998,validation loss:0.618952
epoch 413/600,training loss:0.600947,validation loss:0.618915
epoch 414/600,training loss:0.600949,validation loss:0.618926
epoch 415/600,training loss:0.600882,validation loss:0.618992
epoch 416/600,training loss:0.600868,validation loss:0.618992
epoch 417/600,training loss:0.600823,validation loss:0.618969
epoch 418/600,training loss:0.600793,validation loss:0.619068
epoch 419/600,training loss:0.600797,validation loss:0.619020
epoch 420/600,training loss:0.600697,validation loss:0.619024
epoch 421/600,training loss:0.600744,validation loss:0.619137
epoch 422/600,training loss:0.600745,validation loss:0.619085
epoch 423/600,training loss:0.600608,validation loss:0.619076
epoch 424/600,training loss:0.600625,validation loss:0.619131
epoch 425/600,training loss:0.600569,validation loss:0.619102
epoch 426/600,training loss:0.600575,validation loss:0.619098
epoch 427/600,training loss:0.600514,validation loss:0.619305
epoch 428/600,training loss:0.600512,validation loss:0.619161
epoch 429/600,training loss:0.600442,validation loss:0.619162
epoch 430/600,training loss:0.600449,validation loss:0.619212
epoch 431/600,training loss:0.600397,validation loss:0.619197
epoch 432/600,training loss:0.600362,validation loss:0.619268
epoch 433/600,training loss:0.600324,validation loss:0.619334
epoch 434/600,training loss:0.600326,validation loss:0.619271
epoch 435/600,training loss:0.600293,validation loss:0.619253
epoch 436/600,training loss:0.600237,validation loss:0.619400
epoch 437/600,training loss:0.600172,validation loss:0.619283
epoch 438/600,training loss:0.600136,validation loss:0.619329
epoch 439/600,training loss:0.600168,validation loss:0.619363
epoch 440/600,training loss:0.600138,validation loss:0.619383
epoch 441/600,training loss:0.600082,validation loss:0.619396
epoch 442/600,training loss:0.600069,validation loss:0.619365
epoch 443/600,training loss:0.600064,validation loss:0.619387
epoch 444/600,training loss:0.599948,validation loss:0.619425
epoch 445/600,training loss:0.600011,validation loss:0.619464
epoch 446/600,training loss:0.599951,validation loss:0.619434
epoch 447/600,training loss:0.599859,validation loss:0.619503
epoch 448/600,training loss:0.599861,validation loss:0.619533
epoch 449/600,training loss:0.599885,validation loss:0.619468
epoch 450/600,training loss:0.599895,validation loss:0.619545
epoch 451/600,training loss:0.599770,validation loss:0.619531
epoch 452/600,training loss:0.599726,validation loss:0.619683
epoch 453/600,training loss:0.599747,validation loss:0.619580
epoch 454/600,training loss:0.599688,validation loss:0.619645
epoch 455/600,training loss:0.599644,validation loss:0.619661
epoch 456/600,training loss:0.599691,validation loss:0.619644
epoch 457/600,training loss:0.599594,validation loss:0.619581
epoch 458/600,training loss:0.599569,validation loss:0.619702
epoch 459/600,training loss:0.599539,validation loss:0.619743
epoch 460/600,training loss:0.599560,validation loss:0.619656
epoch 461/600,training loss:0.599553,validation loss:0.619711
epoch 462/600,training loss:0.599492,validation loss:0.619788
epoch 463/600,training loss:0.599436,validation loss:0.619788
epoch 464/600,training loss:0.599398,validation loss:0.619815
epoch 465/600,training loss:0.599372,validation loss:0.619770
epoch 466/600,training loss:0.599378,validation loss:0.619873
epoch 467/600,training loss:0.599304,validation loss:0.619788
epoch 468/600,training loss:0.599336,validation loss:0.619823
epoch 469/600,training loss:0.599276,validation loss:0.619856
epoch 470/600,training loss:0.599231,validation loss:0.619887
epoch 471/600,training loss:0.599209,validation loss:0.620024
epoch 472/600,training loss:0.599200,validation loss:0.620069
epoch 473/600,training loss:0.599172,validation loss:0.619946
epoch 474/600,training loss:0.599158,validation loss:0.619921
epoch 475/600,training loss:0.599161,validation loss:0.619932
epoch 476/600,training loss:0.599090,validation loss:0.619989
epoch 477/600,training loss:0.599074,validation loss:0.620005
epoch 478/600,training loss:0.599004,validation loss:0.619987
epoch 479/600,training loss:0.599020,validation loss:0.620030
epoch 480/600,training loss:0.598990,validation loss:0.620115
epoch 481/600,training loss:0.598916,validation loss:0.620123
epoch 482/600,training loss:0.598897,validation loss:0.620075
epoch 483/600,training loss:0.598926,validation loss:0.620083
epoch 484/600,training loss:0.598866,validation loss:0.620090
epoch 485/600,training loss:0.598828,validation loss:0.620143
epoch 486/600,training loss:0.598835,validation loss:0.620103
epoch 487/600,training loss:0.598787,validation loss:0.620224
epoch 488/600,training loss:0.598765,validation loss:0.620449
epoch 489/600,training loss:0.598732,validation loss:0.620267
epoch 490/600,training loss:0.598733,validation loss:0.620208
epoch 491/600,training loss:0.598643,validation loss:0.620209
epoch 492/600,training loss:0.598606,validation loss:0.620222
epoch 493/600,training loss:0.598593,validation loss:0.620245
epoch 494/600,training loss:0.598718,validation loss:0.620285
epoch 495/600,training loss:0.598613,validation loss:0.620412
epoch 496/600,training loss:0.598587,validation loss:0.620310
epoch 497/600,training loss:0.598492,validation loss:0.620317
epoch 498/600,training loss:0.598529,validation loss:0.620362
epoch 499/600,training loss:0.598439,validation loss:0.620375
epoch 500/600,training loss:0.598464,validation loss:0.620455
epoch 501/600,training loss:0.598448,validation loss:0.620502
epoch 502/600,training loss:0.598404,validation loss:0.620434
epoch 503/600,training loss:0.598357,validation loss:0.620414
epoch 504/600,training loss:0.598267,validation loss:0.620505
epoch 505/600,training loss:0.598310,validation loss:0.620643
epoch 506/600,training loss:0.598309,validation loss:0.620521
epoch 507/600,training loss:0.598288,validation loss:0.620490
epoch 508/600,training loss:0.598197,validation loss:0.620556
epoch 509/600,training loss:0.598255,validation loss:0.620671
epoch 510/600,training loss:0.598241,validation loss:0.620549
epoch 511/600,training loss:0.598133,validation loss:0.620624
epoch 512/600,training loss:0.598133,validation loss:0.620609
epoch 513/600,training loss:0.598145,validation loss:0.620632
epoch 514/600,training loss:0.598069,validation loss:0.620634
epoch 515/600,training loss:0.598133,validation loss:0.620617
epoch 516/600,training loss:0.598045,validation loss:0.620694
epoch 517/600,training loss:0.598022,validation loss:0.620680
epoch 518/600,training loss:0.597979,validation loss:0.620763
epoch 519/600,training loss:0.597932,validation loss:0.620761
epoch 520/600,training loss:0.597907,validation loss:0.620795
epoch 521/600,training loss:0.597950,validation loss:0.620851
epoch 522/600,training loss:0.597897,validation loss:0.620847
epoch 523/600,training loss:0.597827,validation loss:0.620795
epoch 524/600,training loss:0.597850,validation loss:0.620822
epoch 525/600,training loss:0.597788,validation loss:0.621002
epoch 526/600,training loss:0.597804,validation loss:0.620880
epoch 527/600,training loss:0.597791,validation loss:0.620822
epoch 528/600,training loss:0.597732,validation loss:0.620859
epoch 529/600,training loss:0.597767,validation loss:0.620919
epoch 530/600,training loss:0.597726,validation loss:0.620851
epoch 531/600,training loss:0.597673,validation loss:0.620969
epoch 532/600,training loss:0.597659,validation loss:0.620947
epoch 533/600,training loss:0.597652,validation loss:0.620983
epoch 534/600,training loss:0.597625,validation loss:0.620979
epoch 535/600,training loss:0.597603,validation loss:0.621001
epoch 536/600,training loss:0.597512,validation loss:0.620948
epoch 537/600,training loss:0.597561,validation loss:0.621006
epoch 538/600,training loss:0.597512,validation loss:0.621034
epoch 539/600,training loss:0.597516,validation loss:0.621232
epoch 540/600,training loss:0.597523,validation loss:0.621195
epoch 541/600,training loss:0.597413,validation loss:0.621079
epoch 542/600,training loss:0.597409,validation loss:0.621185
epoch 543/600,training loss:0.597411,validation loss:0.621289
epoch 544/600,training loss:0.597380,validation loss:0.621197
epoch 545/600,training loss:0.597359,validation loss:0.621168
epoch 546/600,training loss:0.597302,validation loss:0.621289
epoch 547/600,training loss:0.597318,validation loss:0.621252
epoch 548/600,training loss:0.597302,validation loss:0.621252
epoch 549/600,training loss:0.597258,validation loss:0.621197
epoch 550/600,training loss:0.597234,validation loss:0.621261
epoch 551/600,training loss:0.597202,validation loss:0.621258
epoch 552/600,training loss:0.597228,validation loss:0.621309
epoch 553/600,training loss:0.597167,validation loss:0.621389
epoch 554/600,training loss:0.597106,validation loss:0.621322
epoch 555/600,training loss:0.597136,validation loss:0.621625
epoch 556/600,training loss:0.597142,validation loss:0.621379
epoch 557/600,training loss:0.597076,validation loss:0.621392
epoch 558/600,training loss:0.597002,validation loss:0.621288
epoch 559/600,training loss:0.597045,validation loss:0.621419
epoch 560/600,training loss:0.596980,validation loss:0.621410
epoch 561/600,training loss:0.596978,validation loss:0.621573
epoch 562/600,training loss:0.596948,validation loss:0.621459
epoch 563/600,training loss:0.596926,validation loss:0.621540
epoch 564/600,training loss:0.596890,validation loss:0.621519
epoch 565/600,training loss:0.596923,validation loss:0.621506
epoch 566/600,training loss:0.596787,validation loss:0.621529
epoch 567/600,training loss:0.596817,validation loss:0.621618
epoch 568/600,training loss:0.596847,validation loss:0.621755
epoch 569/600,training loss:0.596816,validation loss:0.621595
epoch 570/600,training loss:0.596737,validation loss:0.621633
epoch 571/600,training loss:0.596717,validation loss:0.621668
epoch 572/600,training loss:0.596720,validation loss:0.621874
epoch 573/600,training loss:0.596712,validation loss:0.621667
epoch 574/600,training loss:0.596700,validation loss:0.621624
epoch 575/600,training loss:0.596715,validation loss:0.621681
epoch 576/600,training loss:0.596602,validation loss:0.621745
epoch 577/600,training loss:0.596526,validation loss:0.621894
epoch 578/600,training loss:0.596590,validation loss:0.621870
epoch 579/600,training loss:0.596593,validation loss:0.621953
epoch 580/600,training loss:0.596532,validation loss:0.621759
epoch 581/600,training loss:0.596471,validation loss:0.621830
epoch 582/600,training loss:0.596500,validation loss:0.621823
epoch 583/600,training loss:0.596454,validation loss:0.621894
epoch 584/600,training loss:0.596426,validation loss:0.621843
epoch 585/600,training loss:0.596447,validation loss:0.621934
epoch 586/600,training loss:0.596430,validation loss:0.621873
epoch 587/600,training loss:0.596383,validation loss:0.621923
epoch 588/600,training loss:0.596390,validation loss:0.621945
epoch 589/600,training loss:0.596337,validation loss:0.621971
epoch 590/600,training loss:0.596316,validation loss:0.621913
epoch 591/600,training loss:0.596313,validation loss:0.621981
epoch 592/600,training loss:0.596230,validation loss:0.621981
epoch 593/600,training loss:0.596223,validation loss:0.622086
epoch 594/600,training loss:0.596253,validation loss:0.622003
epoch 595/600,training loss:0.596232,validation loss:0.622199
epoch 596/600,training loss:0.596226,validation loss:0.622092
epoch 597/600,training loss:0.596183,validation loss:0.622032
epoch 598/600,training loss:0.596167,validation loss:0.622141
epoch 599/600,training loss:0.596116,validation loss:0.622083
Finished. Saving the model to /h/172/shawnlyu/projects/machine_learning/CSC2515Dota2DraftPredictionProject/algorithms/shawn/exp/fc_3.batch.pth
The best validation accuracy occurs at 0th epoch