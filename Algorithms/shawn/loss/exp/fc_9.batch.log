epoch 0/600,training loss:0.690555,validation loss:0.690081
epoch 1/600,training loss:0.689833,validation loss:0.689864
epoch 2/600,training loss:0.689635,validation loss:0.689688
epoch 3/600,training loss:0.689442,validation loss:0.689477
epoch 4/600,training loss:0.689203,validation loss:0.689200
epoch 5/600,training loss:0.688883,validation loss:0.688835
epoch 6/600,training loss:0.688466,validation loss:0.688337
epoch 7/600,training loss:0.687882,validation loss:0.687635
epoch 8/600,training loss:0.687015,validation loss:0.686573
epoch 9/600,training loss:0.685695,validation loss:0.684936
epoch 10/600,training loss:0.683670,validation loss:0.682432
epoch 11/600,training loss:0.680536,validation loss:0.678538
epoch 12/600,training loss:0.675650,validation loss:0.672492
epoch 13/600,training loss:0.668389,validation loss:0.664034
epoch 14/600,training loss:0.659232,validation loss:0.654484
epoch 15/600,training loss:0.650177,validation loss:0.646281
epoch 16/600,training loss:0.643360,validation loss:0.640763
epoch 17/600,training loss:0.638932,validation loss:0.637350
epoch 18/600,training loss:0.636140,validation loss:0.635178
epoch 19/600,training loss:0.634375,validation loss:0.633731
epoch 20/600,training loss:0.633172,validation loss:0.632739
epoch 21/600,training loss:0.632323,validation loss:0.632052
epoch 22/600,training loss:0.631729,validation loss:0.631570
epoch 23/600,training loss:0.631331,validation loss:0.631247
epoch 24/600,training loss:0.630999,validation loss:0.630972
epoch 25/600,training loss:0.630787,validation loss:0.630809
epoch 26/600,training loss:0.630584,validation loss:0.630662
epoch 27/600,training loss:0.630463,validation loss:0.630529
epoch 28/600,training loss:0.630365,validation loss:0.630438
epoch 29/600,training loss:0.630303,validation loss:0.630363
epoch 30/600,training loss:0.630170,validation loss:0.630305
epoch 31/600,training loss:0.630128,validation loss:0.630245
epoch 32/600,training loss:0.630041,validation loss:0.630191
epoch 33/600,training loss:0.629997,validation loss:0.630148
epoch 34/600,training loss:0.629933,validation loss:0.630102
epoch 35/600,training loss:0.629888,validation loss:0.630061
epoch 36/600,training loss:0.629865,validation loss:0.630038
epoch 37/600,training loss:0.629808,validation loss:0.629993
epoch 38/600,training loss:0.629756,validation loss:0.629956
epoch 39/600,training loss:0.629720,validation loss:0.629918
epoch 40/600,training loss:0.629665,validation loss:0.629891
epoch 41/600,training loss:0.629654,validation loss:0.629855
epoch 42/600,training loss:0.629605,validation loss:0.629833
epoch 43/600,training loss:0.629544,validation loss:0.629801
epoch 44/600,training loss:0.629505,validation loss:0.629764
epoch 45/600,training loss:0.629477,validation loss:0.629773
epoch 46/600,training loss:0.629430,validation loss:0.629699
epoch 47/600,training loss:0.629373,validation loss:0.629662
epoch 48/600,training loss:0.629357,validation loss:0.629650
epoch 49/600,training loss:0.629272,validation loss:0.629594
epoch 50/600,training loss:0.629247,validation loss:0.629555
epoch 51/600,training loss:0.629214,validation loss:0.629528
epoch 52/600,training loss:0.629149,validation loss:0.629485
epoch 53/600,training loss:0.629111,validation loss:0.629455
epoch 54/600,training loss:0.629064,validation loss:0.629428
epoch 55/600,training loss:0.628987,validation loss:0.629381
epoch 56/600,training loss:0.629002,validation loss:0.629367
epoch 57/600,training loss:0.628946,validation loss:0.629302
epoch 58/600,training loss:0.628855,validation loss:0.629265
epoch 59/600,training loss:0.628789,validation loss:0.629288
epoch 60/600,training loss:0.628766,validation loss:0.629197
epoch 61/600,training loss:0.628720,validation loss:0.629149
epoch 62/600,training loss:0.628630,validation loss:0.629098
epoch 63/600,training loss:0.628589,validation loss:0.629056
epoch 64/600,training loss:0.628534,validation loss:0.629010
epoch 65/600,training loss:0.628498,validation loss:0.628990
epoch 66/600,training loss:0.628395,validation loss:0.628913
epoch 67/600,training loss:0.628340,validation loss:0.628870
epoch 68/600,training loss:0.628296,validation loss:0.628814
epoch 69/600,training loss:0.628217,validation loss:0.628771
epoch 70/600,training loss:0.628153,validation loss:0.628722
epoch 71/600,training loss:0.628110,validation loss:0.628665
epoch 72/600,training loss:0.628019,validation loss:0.628614
epoch 73/600,training loss:0.628013,validation loss:0.628553
epoch 74/600,training loss:0.627891,validation loss:0.628498
epoch 75/600,training loss:0.627852,validation loss:0.628447
epoch 76/600,training loss:0.627788,validation loss:0.628384
epoch 77/600,training loss:0.627681,validation loss:0.628325
epoch 78/600,training loss:0.627603,validation loss:0.628273
epoch 79/600,training loss:0.627486,validation loss:0.628211
epoch 80/600,training loss:0.627449,validation loss:0.628141
epoch 81/600,training loss:0.627383,validation loss:0.628077
epoch 82/600,training loss:0.627288,validation loss:0.628026
epoch 83/600,training loss:0.627182,validation loss:0.627943
epoch 84/600,training loss:0.627154,validation loss:0.627905
epoch 85/600,training loss:0.627011,validation loss:0.627809
epoch 86/600,training loss:0.626948,validation loss:0.627744
epoch 87/600,training loss:0.626846,validation loss:0.627673
epoch 88/600,training loss:0.626756,validation loss:0.627611
epoch 89/600,training loss:0.626648,validation loss:0.627519
epoch 90/600,training loss:0.626573,validation loss:0.627442
epoch 91/600,training loss:0.626463,validation loss:0.627377
epoch 92/600,training loss:0.626342,validation loss:0.627290
epoch 93/600,training loss:0.626256,validation loss:0.627219
epoch 94/600,training loss:0.626169,validation loss:0.627142
epoch 95/600,training loss:0.626065,validation loss:0.627053
epoch 96/600,training loss:0.625943,validation loss:0.626961
epoch 97/600,training loss:0.625833,validation loss:0.626874
epoch 98/600,training loss:0.625709,validation loss:0.626787
epoch 99/600,training loss:0.625647,validation loss:0.626697
epoch 100/600,training loss:0.625464,validation loss:0.626614
epoch 101/600,training loss:0.625390,validation loss:0.626532
epoch 102/600,training loss:0.625325,validation loss:0.626436
epoch 103/600,training loss:0.625197,validation loss:0.626352
epoch 104/600,training loss:0.625059,validation loss:0.626254
epoch 105/600,training loss:0.624903,validation loss:0.626153
epoch 106/600,training loss:0.624798,validation loss:0.626065
epoch 107/600,training loss:0.624679,validation loss:0.625971
epoch 108/600,training loss:0.624568,validation loss:0.625876
epoch 109/600,training loss:0.624387,validation loss:0.625780
epoch 110/600,training loss:0.624292,validation loss:0.625718
epoch 111/600,training loss:0.624183,validation loss:0.625587
epoch 112/600,training loss:0.624055,validation loss:0.625486
epoch 113/600,training loss:0.623924,validation loss:0.625393
epoch 114/600,training loss:0.623800,validation loss:0.625297
epoch 115/600,training loss:0.623648,validation loss:0.625199
epoch 116/600,training loss:0.623528,validation loss:0.625144
epoch 117/600,training loss:0.623401,validation loss:0.625033
epoch 118/600,training loss:0.623289,validation loss:0.624921
epoch 119/600,training loss:0.623143,validation loss:0.624808
epoch 120/600,training loss:0.622987,validation loss:0.624704
epoch 121/600,training loss:0.622872,validation loss:0.624608
epoch 122/600,training loss:0.622750,validation loss:0.624510
epoch 123/600,training loss:0.622552,validation loss:0.624416
epoch 124/600,training loss:0.622450,validation loss:0.624325
epoch 125/600,training loss:0.622311,validation loss:0.624215
epoch 126/600,training loss:0.622186,validation loss:0.624120
epoch 127/600,training loss:0.622041,validation loss:0.624037
epoch 128/600,training loss:0.621934,validation loss:0.623919
epoch 129/600,training loss:0.621795,validation loss:0.623824
epoch 130/600,training loss:0.621620,validation loss:0.623722
epoch 131/600,training loss:0.621470,validation loss:0.623644
epoch 132/600,training loss:0.621364,validation loss:0.623634
epoch 133/600,training loss:0.621260,validation loss:0.623468
epoch 134/600,training loss:0.621124,validation loss:0.623357
epoch 135/600,training loss:0.620981,validation loss:0.623277
epoch 136/600,training loss:0.620844,validation loss:0.623172
epoch 137/600,training loss:0.620705,validation loss:0.623080
epoch 138/600,training loss:0.620546,validation loss:0.622989
epoch 139/600,training loss:0.620427,validation loss:0.622918
epoch 140/600,training loss:0.620299,validation loss:0.622809
epoch 141/600,training loss:0.620208,validation loss:0.622725
epoch 142/600,training loss:0.620012,validation loss:0.622628
epoch 143/600,training loss:0.619907,validation loss:0.622546
epoch 144/600,training loss:0.619837,validation loss:0.622521
epoch 145/600,training loss:0.619656,validation loss:0.622389
epoch 146/600,training loss:0.619536,validation loss:0.622310
epoch 147/600,training loss:0.619398,validation loss:0.622223
epoch 148/600,training loss:0.619287,validation loss:0.622145
epoch 149/600,training loss:0.619216,validation loss:0.622078
epoch 150/600,training loss:0.619043,validation loss:0.621989
epoch 151/600,training loss:0.618919,validation loss:0.621912
epoch 152/600,training loss:0.618794,validation loss:0.621840
epoch 153/600,training loss:0.618648,validation loss:0.621780
epoch 154/600,training loss:0.618550,validation loss:0.621673
epoch 155/600,training loss:0.618437,validation loss:0.621628
epoch 156/600,training loss:0.618272,validation loss:0.621533
epoch 157/600,training loss:0.618189,validation loss:0.621460
epoch 158/600,training loss:0.618005,validation loss:0.621390
epoch 159/600,training loss:0.617937,validation loss:0.621319
epoch 160/600,training loss:0.617841,validation loss:0.621275
epoch 161/600,training loss:0.617676,validation loss:0.621183
epoch 162/600,training loss:0.617581,validation loss:0.621121
epoch 163/600,training loss:0.617459,validation loss:0.621053
epoch 164/600,training loss:0.617315,validation loss:0.620992
epoch 165/600,training loss:0.617219,validation loss:0.620933
epoch 166/600,training loss:0.617130,validation loss:0.620909
epoch 167/600,training loss:0.617015,validation loss:0.620818
epoch 168/600,training loss:0.616885,validation loss:0.620747
epoch 169/600,training loss:0.616755,validation loss:0.620697
epoch 170/600,training loss:0.616625,validation loss:0.620649
epoch 171/600,training loss:0.616570,validation loss:0.620586
epoch 172/600,training loss:0.616397,validation loss:0.620542
epoch 173/600,training loss:0.616305,validation loss:0.620500
epoch 174/600,training loss:0.616241,validation loss:0.620421
epoch 175/600,training loss:0.616083,validation loss:0.620381
epoch 176/600,training loss:0.615999,validation loss:0.620316
epoch 177/600,training loss:0.615901,validation loss:0.620258
epoch 178/600,training loss:0.615763,validation loss:0.620247
epoch 179/600,training loss:0.615698,validation loss:0.620145
epoch 180/600,training loss:0.615578,validation loss:0.620123
epoch 181/600,training loss:0.615467,validation loss:0.620067
epoch 182/600,training loss:0.615338,validation loss:0.620041
epoch 183/600,training loss:0.615268,validation loss:0.619996
epoch 184/600,training loss:0.615156,validation loss:0.619936
epoch 185/600,training loss:0.615062,validation loss:0.619917
epoch 186/600,training loss:0.614946,validation loss:0.619851
epoch 187/600,training loss:0.614826,validation loss:0.619824
epoch 188/600,training loss:0.614771,validation loss:0.619746
epoch 189/600,training loss:0.614659,validation loss:0.619702
epoch 190/600,training loss:0.614532,validation loss:0.619708
epoch 191/600,training loss:0.614462,validation loss:0.619607
epoch 192/600,training loss:0.614344,validation loss:0.619636
epoch 193/600,training loss:0.614285,validation loss:0.619541
epoch 194/600,training loss:0.614177,validation loss:0.619512
epoch 195/600,training loss:0.614075,validation loss:0.619478
epoch 196/600,training loss:0.613937,validation loss:0.619441
epoch 197/600,training loss:0.613872,validation loss:0.619383
epoch 198/600,training loss:0.613824,validation loss:0.619349
epoch 199/600,training loss:0.613725,validation loss:0.619362
epoch 200/600,training loss:0.613608,validation loss:0.619284
epoch 201/600,training loss:0.613503,validation loss:0.619256
epoch 202/600,training loss:0.613409,validation loss:0.619260
epoch 203/600,training loss:0.613349,validation loss:0.619202
epoch 204/600,training loss:0.613263,validation loss:0.619184
epoch 205/600,training loss:0.613151,validation loss:0.619139
epoch 206/600,training loss:0.613029,validation loss:0.619129
epoch 207/600,training loss:0.612997,validation loss:0.619057
epoch 208/600,training loss:0.612864,validation loss:0.619026
epoch 209/600,training loss:0.612802,validation loss:0.618989
epoch 210/600,training loss:0.612712,validation loss:0.618970
epoch 211/600,training loss:0.612616,validation loss:0.618947
epoch 212/600,training loss:0.612589,validation loss:0.618968
epoch 213/600,training loss:0.612424,validation loss:0.618923
epoch 214/600,training loss:0.612335,validation loss:0.618891
epoch 215/600,training loss:0.612236,validation loss:0.618823
epoch 216/600,training loss:0.612184,validation loss:0.618827
epoch 217/600,training loss:0.612153,validation loss:0.618783
epoch 218/600,training loss:0.612001,validation loss:0.618819
epoch 219/600,training loss:0.611948,validation loss:0.618734
epoch 220/600,training loss:0.611866,validation loss:0.618704
epoch 221/600,training loss:0.611813,validation loss:0.618699
epoch 222/600,training loss:0.611716,validation loss:0.618649
epoch 223/600,training loss:0.611627,validation loss:0.618615
epoch 224/600,training loss:0.611527,validation loss:0.618612
epoch 225/600,training loss:0.611446,validation loss:0.618586
epoch 226/600,training loss:0.611379,validation loss:0.618602
epoch 227/600,training loss:0.611314,validation loss:0.618530
epoch 228/600,training loss:0.611207,validation loss:0.618532
epoch 229/600,training loss:0.611164,validation loss:0.618626
epoch 230/600,training loss:0.611059,validation loss:0.618476
epoch 231/600,training loss:0.610951,validation loss:0.618430
epoch 232/600,training loss:0.610897,validation loss:0.618455
epoch 233/600,training loss:0.610827,validation loss:0.618457
epoch 234/600,training loss:0.610736,validation loss:0.618417
epoch 235/600,training loss:0.610712,validation loss:0.618401
epoch 236/600,training loss:0.610616,validation loss:0.618348
epoch 237/600,training loss:0.610531,validation loss:0.618358
epoch 238/600,training loss:0.610498,validation loss:0.618317
epoch 239/600,training loss:0.610355,validation loss:0.618320
epoch 240/600,training loss:0.610305,validation loss:0.618301
epoch 241/600,training loss:0.610205,validation loss:0.618261
epoch 242/600,training loss:0.610167,validation loss:0.618296
epoch 243/600,training loss:0.610090,validation loss:0.618262
epoch 244/600,training loss:0.610017,validation loss:0.618241
epoch 245/600,training loss:0.609945,validation loss:0.618231
epoch 246/600,training loss:0.609875,validation loss:0.618233
epoch 247/600,training loss:0.609839,validation loss:0.618211
epoch 248/600,training loss:0.609719,validation loss:0.618252
epoch 249/600,training loss:0.609680,validation loss:0.618174
epoch 250/600,training loss:0.609600,validation loss:0.618185
epoch 251/600,training loss:0.609524,validation loss:0.618137
epoch 252/600,training loss:0.609435,validation loss:0.618139
epoch 253/600,training loss:0.609352,validation loss:0.618219
epoch 254/600,training loss:0.609297,validation loss:0.618148
epoch 255/600,training loss:0.609280,validation loss:0.618096
epoch 256/600,training loss:0.609212,validation loss:0.618061
epoch 257/600,training loss:0.609141,validation loss:0.618091
epoch 258/600,training loss:0.609065,validation loss:0.618102
epoch 259/600,training loss:0.608959,validation loss:0.618043
epoch 260/600,training loss:0.608908,validation loss:0.618065
epoch 261/600,training loss:0.608787,validation loss:0.618041
epoch 262/600,training loss:0.608805,validation loss:0.618033
epoch 263/600,training loss:0.608760,validation loss:0.618029
epoch 264/600,training loss:0.608637,validation loss:0.618048
epoch 265/600,training loss:0.608593,validation loss:0.618005
epoch 266/600,training loss:0.608529,validation loss:0.617995
epoch 267/600,training loss:0.608469,validation loss:0.618071
epoch 268/600,training loss:0.608400,validation loss:0.617992
epoch 269/600,training loss:0.608335,validation loss:0.618002
epoch 270/600,training loss:0.608260,validation loss:0.618044
epoch 271/600,training loss:0.608192,validation loss:0.617990
epoch 272/600,training loss:0.608166,validation loss:0.617944
epoch 273/600,training loss:0.608075,validation loss:0.618021
epoch 274/600,training loss:0.608015,validation loss:0.617946
epoch 275/600,training loss:0.607991,validation loss:0.618008
epoch 276/600,training loss:0.607923,validation loss:0.617927
epoch 277/600,training loss:0.607858,validation loss:0.617971
epoch 278/600,training loss:0.607800,validation loss:0.617935
epoch 279/600,training loss:0.607743,validation loss:0.617990
epoch 280/600,training loss:0.607673,validation loss:0.618014
epoch 281/600,training loss:0.607641,validation loss:0.617955
epoch 282/600,training loss:0.607540,validation loss:0.617988
epoch 283/600,training loss:0.607498,validation loss:0.617945
epoch 284/600,training loss:0.607469,validation loss:0.617970
epoch 285/600,training loss:0.607379,validation loss:0.617971
epoch 286/600,training loss:0.607330,validation loss:0.618027
epoch 287/600,training loss:0.607268,validation loss:0.617977
epoch 288/600,training loss:0.607211,validation loss:0.617902
epoch 289/600,training loss:0.607176,validation loss:0.617926
epoch 290/600,training loss:0.607044,validation loss:0.617919
epoch 291/600,training loss:0.607053,validation loss:0.617949
epoch 292/600,training loss:0.606954,validation loss:0.617935
epoch 293/600,training loss:0.606913,validation loss:0.617968
epoch 294/600,training loss:0.606864,validation loss:0.617936
epoch 295/600,training loss:0.606809,validation loss:0.617907
epoch 296/600,training loss:0.606699,validation loss:0.617886
epoch 297/600,training loss:0.606670,validation loss:0.617932
epoch 298/600,training loss:0.606663,validation loss:0.617895
epoch 299/600,training loss:0.606617,validation loss:0.617912
epoch 300/600,training loss:0.606502,validation loss:0.617917
epoch 301/600,training loss:0.606461,validation loss:0.617923
epoch 302/600,training loss:0.606387,validation loss:0.617918
epoch 303/600,training loss:0.606346,validation loss:0.617918
epoch 304/600,training loss:0.606296,validation loss:0.617946
epoch 305/600,training loss:0.606283,validation loss:0.617899
epoch 306/600,training loss:0.606239,validation loss:0.618110
epoch 307/600,training loss:0.606191,validation loss:0.617898
epoch 308/600,training loss:0.606130,validation loss:0.617938
epoch 309/600,training loss:0.606050,validation loss:0.617991
epoch 310/600,training loss:0.606006,validation loss:0.617959
epoch 311/600,training loss:0.605967,validation loss:0.617907
epoch 312/600,training loss:0.605945,validation loss:0.617928
epoch 313/600,training loss:0.605822,validation loss:0.617990
epoch 314/600,training loss:0.605841,validation loss:0.617949
epoch 315/600,training loss:0.605763,validation loss:0.618038
epoch 316/600,training loss:0.605710,validation loss:0.618006
epoch 317/600,training loss:0.605658,validation loss:0.617969
epoch 318/600,training loss:0.605615,validation loss:0.617972
epoch 319/600,training loss:0.605571,validation loss:0.617976
epoch 320/600,training loss:0.605499,validation loss:0.617969
epoch 321/600,training loss:0.605482,validation loss:0.617982
epoch 322/600,training loss:0.605376,validation loss:0.618013
epoch 323/600,training loss:0.605367,validation loss:0.617973
epoch 324/600,training loss:0.605276,validation loss:0.618024
epoch 325/600,training loss:0.605285,validation loss:0.618108
epoch 326/600,training loss:0.605188,validation loss:0.617993
epoch 327/600,training loss:0.605182,validation loss:0.618026
epoch 328/600,training loss:0.605174,validation loss:0.617993
epoch 329/600,training loss:0.605067,validation loss:0.618034
epoch 330/600,training loss:0.605061,validation loss:0.618040
epoch 331/600,training loss:0.604951,validation loss:0.618053
epoch 332/600,training loss:0.604965,validation loss:0.618028
epoch 333/600,training loss:0.604923,validation loss:0.618298
epoch 334/600,training loss:0.604847,validation loss:0.618019
epoch 335/600,training loss:0.604861,validation loss:0.618128
epoch 336/600,training loss:0.604780,validation loss:0.618059
epoch 337/600,training loss:0.604728,validation loss:0.618080
epoch 338/600,training loss:0.604643,validation loss:0.618043
epoch 339/600,training loss:0.604584,validation loss:0.618062
epoch 340/600,training loss:0.604550,validation loss:0.618122
epoch 341/600,training loss:0.604508,validation loss:0.618051
epoch 342/600,training loss:0.604487,validation loss:0.618219
epoch 343/600,training loss:0.604418,validation loss:0.618197
epoch 344/600,training loss:0.604414,validation loss:0.618197
epoch 345/600,training loss:0.604352,validation loss:0.618127
epoch 346/600,training loss:0.604277,validation loss:0.618149
epoch 347/600,training loss:0.604224,validation loss:0.618225
epoch 348/600,training loss:0.604190,validation loss:0.618166
epoch 349/600,training loss:0.604144,validation loss:0.618137
epoch 350/600,training loss:0.604108,validation loss:0.618194
epoch 351/600,training loss:0.604109,validation loss:0.618149
epoch 352/600,training loss:0.604006,validation loss:0.618187
epoch 353/600,training loss:0.603964,validation loss:0.618186
epoch 354/600,training loss:0.603899,validation loss:0.618317
epoch 355/600,training loss:0.603890,validation loss:0.618189
epoch 356/600,training loss:0.603897,validation loss:0.618398
epoch 357/600,training loss:0.603833,validation loss:0.618193
epoch 358/600,training loss:0.603767,validation loss:0.618185
epoch 359/600,training loss:0.603758,validation loss:0.618213
epoch 360/600,training loss:0.603687,validation loss:0.618251
epoch 361/600,training loss:0.603647,validation loss:0.618245
epoch 362/600,training loss:0.603598,validation loss:0.618244
epoch 363/600,training loss:0.603608,validation loss:0.618444
epoch 364/600,training loss:0.603547,validation loss:0.618259
epoch 365/600,training loss:0.603461,validation loss:0.618322
epoch 366/600,training loss:0.603477,validation loss:0.618328
epoch 367/600,training loss:0.603367,validation loss:0.618381
epoch 368/600,training loss:0.603348,validation loss:0.618332
epoch 369/600,training loss:0.603327,validation loss:0.618330
epoch 370/600,training loss:0.603316,validation loss:0.618285
epoch 371/600,training loss:0.603185,validation loss:0.618359
epoch 372/600,training loss:0.603211,validation loss:0.618336
epoch 373/600,training loss:0.603148,validation loss:0.618354
epoch 374/600,training loss:0.603112,validation loss:0.618378
epoch 375/600,training loss:0.603065,validation loss:0.618398
epoch 376/600,training loss:0.603068,validation loss:0.618416
epoch 377/600,training loss:0.603026,validation loss:0.618467
epoch 378/600,training loss:0.602991,validation loss:0.618389
epoch 379/600,training loss:0.602904,validation loss:0.618399
epoch 380/600,training loss:0.602887,validation loss:0.618402
epoch 381/600,training loss:0.602851,validation loss:0.618582
epoch 382/600,training loss:0.602847,validation loss:0.618459
epoch 383/600,training loss:0.602804,validation loss:0.618480
epoch 384/600,training loss:0.602749,validation loss:0.618527
epoch 385/600,training loss:0.602683,validation loss:0.618519
epoch 386/600,training loss:0.602685,validation loss:0.618504
epoch 387/600,training loss:0.602603,validation loss:0.618743
epoch 388/600,training loss:0.602609,validation loss:0.618539
epoch 389/600,training loss:0.602574,validation loss:0.618547
epoch 390/600,training loss:0.602482,validation loss:0.618518
epoch 391/600,training loss:0.602467,validation loss:0.618531
epoch 392/600,training loss:0.602451,validation loss:0.618548
epoch 393/600,training loss:0.602397,validation loss:0.618640
epoch 394/600,training loss:0.602367,validation loss:0.618680
epoch 395/600,training loss:0.602302,validation loss:0.618628
epoch 396/600,training loss:0.602255,validation loss:0.618640
epoch 397/600,training loss:0.602286,validation loss:0.618631
epoch 398/600,training loss:0.602261,validation loss:0.618665
epoch 399/600,training loss:0.602207,validation loss:0.618715
epoch 400/600,training loss:0.602185,validation loss:0.618715
epoch 401/600,training loss:0.602126,validation loss:0.618689
epoch 402/600,training loss:0.602028,validation loss:0.618728
epoch 403/600,training loss:0.602049,validation loss:0.618688
epoch 404/600,training loss:0.601967,validation loss:0.618724
epoch 405/600,training loss:0.601975,validation loss:0.618738
epoch 406/600,training loss:0.601936,validation loss:0.618761
epoch 407/600,training loss:0.601891,validation loss:0.618779
epoch 408/600,training loss:0.601857,validation loss:0.618783
epoch 409/600,training loss:0.601805,validation loss:0.618845
epoch 410/600,training loss:0.601815,validation loss:0.618760
epoch 411/600,training loss:0.601686,validation loss:0.618828
epoch 412/600,training loss:0.601684,validation loss:0.618858
epoch 413/600,training loss:0.601702,validation loss:0.618810
epoch 414/600,training loss:0.601637,validation loss:0.618841
epoch 415/600,training loss:0.601610,validation loss:0.618841
epoch 416/600,training loss:0.601557,validation loss:0.618876
epoch 417/600,training loss:0.601576,validation loss:0.618915
epoch 418/600,training loss:0.601492,validation loss:0.618922
epoch 419/600,training loss:0.601405,validation loss:0.618926
epoch 420/600,training loss:0.601452,validation loss:0.618926
epoch 421/600,training loss:0.601412,validation loss:0.619057
epoch 422/600,training loss:0.601391,validation loss:0.618970
epoch 423/600,training loss:0.601340,validation loss:0.619074
epoch 424/600,training loss:0.601299,validation loss:0.619112
epoch 425/600,training loss:0.601276,validation loss:0.619080
epoch 426/600,training loss:0.601267,validation loss:0.619072
epoch 427/600,training loss:0.601198,validation loss:0.619031
epoch 428/600,training loss:0.601175,validation loss:0.619076
epoch 429/600,training loss:0.601116,validation loss:0.619083
epoch 430/600,training loss:0.601110,validation loss:0.619048
epoch 431/600,training loss:0.601027,validation loss:0.619074
epoch 432/600,training loss:0.601033,validation loss:0.619115
epoch 433/600,training loss:0.600983,validation loss:0.619131
epoch 434/600,training loss:0.600950,validation loss:0.619210
epoch 435/600,training loss:0.600963,validation loss:0.619169
epoch 436/600,training loss:0.600891,validation loss:0.619174
epoch 437/600,training loss:0.600843,validation loss:0.619190
epoch 438/600,training loss:0.600834,validation loss:0.619200
epoch 439/600,training loss:0.600805,validation loss:0.619226
epoch 440/600,training loss:0.600726,validation loss:0.619295
epoch 441/600,training loss:0.600742,validation loss:0.619216
epoch 442/600,training loss:0.600729,validation loss:0.619267
epoch 443/600,training loss:0.600691,validation loss:0.619326
epoch 444/600,training loss:0.600613,validation loss:0.619359
epoch 445/600,training loss:0.600609,validation loss:0.619312
epoch 446/600,training loss:0.600616,validation loss:0.619327
epoch 447/600,training loss:0.600603,validation loss:0.619404
epoch 448/600,training loss:0.600509,validation loss:0.619362
epoch 449/600,training loss:0.600454,validation loss:0.619333
epoch 450/600,training loss:0.600450,validation loss:0.619437
epoch 451/600,training loss:0.600392,validation loss:0.619456
epoch 452/600,training loss:0.600416,validation loss:0.619432
epoch 453/600,training loss:0.600359,validation loss:0.619474
epoch 454/600,training loss:0.600286,validation loss:0.619497
epoch 455/600,training loss:0.600306,validation loss:0.619453
epoch 456/600,training loss:0.600242,validation loss:0.619494
epoch 457/600,training loss:0.600238,validation loss:0.619483
epoch 458/600,training loss:0.600181,validation loss:0.619489
epoch 459/600,training loss:0.600167,validation loss:0.619519
epoch 460/600,training loss:0.600130,validation loss:0.619508
epoch 461/600,training loss:0.600060,validation loss:0.619541
epoch 462/600,training loss:0.600071,validation loss:0.619635
epoch 463/600,training loss:0.600049,validation loss:0.619618
epoch 464/600,training loss:0.600030,validation loss:0.619598
epoch 465/600,training loss:0.599945,validation loss:0.619611
epoch 466/600,training loss:0.599917,validation loss:0.619625
epoch 467/600,training loss:0.599915,validation loss:0.619628
epoch 468/600,training loss:0.599857,validation loss:0.619732
epoch 469/600,training loss:0.599898,validation loss:0.619727
epoch 470/600,training loss:0.599842,validation loss:0.619718
epoch 471/600,training loss:0.599848,validation loss:0.619784
epoch 472/600,training loss:0.599754,validation loss:0.619713
epoch 473/600,training loss:0.599742,validation loss:0.619813
epoch 474/600,training loss:0.599702,validation loss:0.619808
epoch 475/600,training loss:0.599701,validation loss:0.619799
epoch 476/600,training loss:0.599630,validation loss:0.619822
epoch 477/600,training loss:0.599615,validation loss:0.619839
epoch 478/600,training loss:0.599607,validation loss:0.619873
epoch 479/600,training loss:0.599561,validation loss:0.619818
epoch 480/600,training loss:0.599486,validation loss:0.619823
epoch 481/600,training loss:0.599544,validation loss:0.619955
epoch 482/600,training loss:0.599503,validation loss:0.619877
epoch 483/600,training loss:0.599409,validation loss:0.620092
epoch 484/600,training loss:0.599506,validation loss:0.619961
epoch 485/600,training loss:0.599334,validation loss:0.619882
epoch 486/600,training loss:0.599345,validation loss:0.619980
epoch 487/600,training loss:0.599356,validation loss:0.620140
epoch 488/600,training loss:0.599255,validation loss:0.620027
epoch 489/600,training loss:0.599225,validation loss:0.619938
epoch 490/600,training loss:0.599202,validation loss:0.619981
epoch 491/600,training loss:0.599224,validation loss:0.620071
epoch 492/600,training loss:0.599211,validation loss:0.620007
epoch 493/600,training loss:0.599136,validation loss:0.620048
epoch 494/600,training loss:0.599101,validation loss:0.620196
epoch 495/600,training loss:0.599062,validation loss:0.620094
epoch 496/600,training loss:0.599095,validation loss:0.620054
epoch 497/600,training loss:0.599065,validation loss:0.620120
epoch 498/600,training loss:0.599012,validation loss:0.620275
epoch 499/600,training loss:0.598969,validation loss:0.620178
epoch 500/600,training loss:0.598916,validation loss:0.620270
epoch 501/600,training loss:0.598901,validation loss:0.620199
epoch 502/600,training loss:0.598848,validation loss:0.620266
epoch 503/600,training loss:0.598852,validation loss:0.620203
epoch 504/600,training loss:0.598858,validation loss:0.620161
epoch 505/600,training loss:0.598790,validation loss:0.620228
epoch 506/600,training loss:0.598755,validation loss:0.620295
epoch 507/600,training loss:0.598767,validation loss:0.620306
epoch 508/600,training loss:0.598716,validation loss:0.620260
epoch 509/600,training loss:0.598720,validation loss:0.620484
epoch 510/600,training loss:0.598681,validation loss:0.620334
epoch 511/600,training loss:0.598656,validation loss:0.620307
epoch 512/600,training loss:0.598623,validation loss:0.620313
epoch 513/600,training loss:0.598567,validation loss:0.620328
epoch 514/600,training loss:0.598549,validation loss:0.620441
epoch 515/600,training loss:0.598535,validation loss:0.620396
epoch 516/600,training loss:0.598482,validation loss:0.620467
epoch 517/600,training loss:0.598452,validation loss:0.620565
epoch 518/600,training loss:0.598472,validation loss:0.620453
epoch 519/600,training loss:0.598387,validation loss:0.620522
epoch 520/600,training loss:0.598319,validation loss:0.620446
epoch 521/600,training loss:0.598291,validation loss:0.620508
epoch 522/600,training loss:0.598320,validation loss:0.620552
epoch 523/600,training loss:0.598294,validation loss:0.620572
epoch 524/600,training loss:0.598259,validation loss:0.620603
epoch 525/600,training loss:0.598236,validation loss:0.620637
epoch 526/600,training loss:0.598198,validation loss:0.620599
epoch 527/600,training loss:0.598183,validation loss:0.620654
epoch 528/600,training loss:0.598221,validation loss:0.620623
epoch 529/600,training loss:0.598164,validation loss:0.620708
epoch 530/600,training loss:0.598114,validation loss:0.620749
epoch 531/600,training loss:0.598100,validation loss:0.620738
epoch 532/600,training loss:0.598019,validation loss:0.620697
epoch 533/600,training loss:0.598010,validation loss:0.620722
epoch 534/600,training loss:0.598018,validation loss:0.620747
epoch 535/600,training loss:0.597926,validation loss:0.620756
epoch 536/600,training loss:0.597978,validation loss:0.620828
epoch 537/600,training loss:0.597952,validation loss:0.620832
epoch 538/600,training loss:0.597860,validation loss:0.620781
epoch 539/600,training loss:0.597872,validation loss:0.620796
epoch 540/600,training loss:0.597815,validation loss:0.620840
epoch 541/600,training loss:0.597787,validation loss:0.620833
epoch 542/600,training loss:0.597774,validation loss:0.620959
epoch 543/600,training loss:0.597776,validation loss:0.620922
epoch 544/600,training loss:0.597730,validation loss:0.620933
epoch 545/600,training loss:0.597706,validation loss:0.620896
epoch 546/600,training loss:0.597663,validation loss:0.620920
epoch 547/600,training loss:0.597654,validation loss:0.620923
epoch 548/600,training loss:0.597623,validation loss:0.621032
epoch 549/600,training loss:0.597597,validation loss:0.621138
epoch 550/600,training loss:0.597632,validation loss:0.621000
epoch 551/600,training loss:0.597495,validation loss:0.621050
epoch 552/600,training loss:0.597524,validation loss:0.621032
epoch 553/600,training loss:0.597519,validation loss:0.621094
epoch 554/600,training loss:0.597433,validation loss:0.621076
epoch 555/600,training loss:0.597402,validation loss:0.621123
epoch 556/600,training loss:0.597429,validation loss:0.621082
epoch 557/600,training loss:0.597373,validation loss:0.621110
epoch 558/600,training loss:0.597399,validation loss:0.621111
epoch 559/600,training loss:0.597321,validation loss:0.621136
epoch 560/600,training loss:0.597302,validation loss:0.621305
epoch 561/600,training loss:0.597302,validation loss:0.621238
epoch 562/600,training loss:0.597288,validation loss:0.621242
epoch 563/600,training loss:0.597238,validation loss:0.621316
epoch 564/600,training loss:0.597225,validation loss:0.621298
epoch 565/600,training loss:0.597160,validation loss:0.621343
epoch 566/600,training loss:0.597245,validation loss:0.621263
epoch 567/600,training loss:0.597196,validation loss:0.621251
epoch 568/600,training loss:0.597112,validation loss:0.621332
epoch 569/600,training loss:0.597162,validation loss:0.621392
epoch 570/600,training loss:0.597122,validation loss:0.621377
epoch 571/600,training loss:0.597085,validation loss:0.621465
epoch 572/600,training loss:0.597047,validation loss:0.621440
epoch 573/600,training loss:0.596979,validation loss:0.621357
epoch 574/600,training loss:0.596935,validation loss:0.621368
epoch 575/600,training loss:0.596937,validation loss:0.621469
epoch 576/600,training loss:0.596966,validation loss:0.621469
epoch 577/600,training loss:0.596842,validation loss:0.621524
epoch 578/600,training loss:0.596844,validation loss:0.621534
epoch 579/600,training loss:0.596831,validation loss:0.621582
epoch 580/600,training loss:0.596862,validation loss:0.621590
epoch 581/600,training loss:0.596748,validation loss:0.621631
epoch 582/600,training loss:0.596788,validation loss:0.621560
epoch 583/600,training loss:0.596778,validation loss:0.621587
epoch 584/600,training loss:0.596704,validation loss:0.621564
epoch 585/600,training loss:0.596665,validation loss:0.621645
epoch 586/600,training loss:0.596688,validation loss:0.621607
epoch 587/600,training loss:0.596643,validation loss:0.621602
epoch 588/600,training loss:0.596587,validation loss:0.621613
epoch 589/600,training loss:0.596597,validation loss:0.621853
epoch 590/600,training loss:0.596599,validation loss:0.621701
epoch 591/600,training loss:0.596581,validation loss:0.621738
epoch 592/600,training loss:0.596515,validation loss:0.621743
epoch 593/600,training loss:0.596477,validation loss:0.621809
epoch 594/600,training loss:0.596516,validation loss:0.621754
epoch 595/600,training loss:0.596396,validation loss:0.621750
epoch 596/600,training loss:0.596438,validation loss:0.621853
epoch 597/600,training loss:0.596445,validation loss:0.621880
epoch 598/600,training loss:0.596404,validation loss:0.621984
epoch 599/600,training loss:0.596347,validation loss:0.622024
Finished. Saving the model to /h/172/shawnlyu/projects/machine_learning/CSC2515Dota2DraftPredictionProject/algorithms/shawn/exp/fc_9.batch.pth
The best validation accuracy occurs at 0th epoch