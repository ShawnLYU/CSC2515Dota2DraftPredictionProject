epoch 0/200,training loss:0.710069,validation loss:0.696234
epoch 1/200,training loss:0.693787,validation loss:0.693081
epoch 2/200,training loss:0.692556,validation loss:0.692361
epoch 3/200,training loss:0.691999,validation loss:0.691799
epoch 4/200,training loss:0.691593,validation loss:0.691551
epoch 5/200,training loss:0.691173,validation loss:0.691123
epoch 6/200,training loss:0.690716,validation loss:0.690670
epoch 7/200,training loss:0.690240,validation loss:0.690215
epoch 8/200,training loss:0.689771,validation loss:0.689508
epoch 9/200,training loss:0.689160,validation loss:0.689112
epoch 10/200,training loss:0.688654,validation loss:0.688407
epoch 11/200,training loss:0.687998,validation loss:0.687832
epoch 12/200,training loss:0.687310,validation loss:0.687218
epoch 13/200,training loss:0.686879,validation loss:0.686560
epoch 14/200,training loss:0.686360,validation loss:0.686190
epoch 15/200,training loss:0.685657,validation loss:0.685561
epoch 16/200,training loss:0.684851,validation loss:0.684915
epoch 17/200,training loss:0.684480,validation loss:0.684511
epoch 18/200,training loss:0.683823,validation loss:0.683548
epoch 19/200,training loss:0.683386,validation loss:0.683566
epoch 20/200,training loss:0.682651,validation loss:0.683001
epoch 21/200,training loss:0.682430,validation loss:0.682421
epoch 22/200,training loss:0.681910,validation loss:0.681887
epoch 23/200,training loss:0.681428,validation loss:0.681312
epoch 24/200,training loss:0.680993,validation loss:0.681223
epoch 25/200,training loss:0.680404,validation loss:0.680363
epoch 26/200,training loss:0.680150,validation loss:0.679899
epoch 27/200,training loss:0.679467,validation loss:0.679541
epoch 28/200,training loss:0.679191,validation loss:0.678968
epoch 29/200,training loss:0.678871,validation loss:0.679052
epoch 30/200,training loss:0.678385,validation loss:0.678363
epoch 31/200,training loss:0.677915,validation loss:0.677909
epoch 32/200,training loss:0.677413,validation loss:0.677887
epoch 33/200,training loss:0.677274,validation loss:0.677487
epoch 34/200,training loss:0.676752,validation loss:0.677177
epoch 35/200,training loss:0.676257,validation loss:0.676834
epoch 36/200,training loss:0.676323,validation loss:0.676454
epoch 37/200,training loss:0.675984,validation loss:0.676764
epoch 38/200,training loss:0.675528,validation loss:0.675909
epoch 39/200,training loss:0.675369,validation loss:0.675716
epoch 40/200,training loss:0.675157,validation loss:0.675280
epoch 41/200,training loss:0.674751,validation loss:0.674844
epoch 42/200,training loss:0.674693,validation loss:0.674656
epoch 43/200,training loss:0.673901,validation loss:0.674207
epoch 44/200,training loss:0.674119,validation loss:0.674498
epoch 45/200,training loss:0.673682,validation loss:0.674094
epoch 46/200,training loss:0.673727,validation loss:0.673969
epoch 47/200,training loss:0.673300,validation loss:0.673824
epoch 48/200,training loss:0.673188,validation loss:0.673842
epoch 49/200,training loss:0.672940,validation loss:0.673197
epoch 50/200,training loss:0.672628,validation loss:0.673067
epoch 51/200,training loss:0.672319,validation loss:0.673024
epoch 52/200,training loss:0.672407,validation loss:0.673086
epoch 53/200,training loss:0.671958,validation loss:0.672746
epoch 54/200,training loss:0.671947,validation loss:0.672439
epoch 55/200,training loss:0.671915,validation loss:0.671888
epoch 56/200,training loss:0.671942,validation loss:0.672166
epoch 57/200,training loss:0.671540,validation loss:0.671902
epoch 58/200,training loss:0.671657,validation loss:0.672115
epoch 59/200,training loss:0.671044,validation loss:0.671799
epoch 60/200,training loss:0.671119,validation loss:0.671307
epoch 61/200,training loss:0.670961,validation loss:0.671536
epoch 62/200,training loss:0.670801,validation loss:0.671067
epoch 63/200,training loss:0.670692,validation loss:0.671195
epoch 64/200,training loss:0.670510,validation loss:0.671035
epoch 65/200,training loss:0.670721,validation loss:0.670757
epoch 66/200,training loss:0.670437,validation loss:0.671218
epoch 67/200,training loss:0.670451,validation loss:0.670283
epoch 68/200,training loss:0.670122,validation loss:0.670662
epoch 69/200,training loss:0.669852,validation loss:0.670347
epoch 70/200,training loss:0.669808,validation loss:0.669913
epoch 71/200,training loss:0.669725,validation loss:0.670389
epoch 72/200,training loss:0.669776,validation loss:0.669851
epoch 73/200,training loss:0.669814,validation loss:0.669980
epoch 74/200,training loss:0.669336,validation loss:0.670180
epoch 75/200,training loss:0.669556,validation loss:0.670110
epoch 76/200,training loss:0.669468,validation loss:0.669466
epoch 77/200,training loss:0.669055,validation loss:0.669682
epoch 78/200,training loss:0.669051,validation loss:0.669504
epoch 79/200,training loss:0.668858,validation loss:0.669150
epoch 80/200,training loss:0.669071,validation loss:0.669045
epoch 81/200,training loss:0.668851,validation loss:0.669409
epoch 82/200,training loss:0.668636,validation loss:0.668854
epoch 83/200,training loss:0.668878,validation loss:0.669043
epoch 84/200,training loss:0.668356,validation loss:0.669029
epoch 85/200,training loss:0.668353,validation loss:0.669204
epoch 86/200,training loss:0.668436,validation loss:0.669479
epoch 87/200,training loss:0.668333,validation loss:0.669065
epoch 88/200,training loss:0.668583,validation loss:0.668625
epoch 89/200,training loss:0.668456,validation loss:0.668662
epoch 90/200,training loss:0.668138,validation loss:0.668471
epoch 91/200,training loss:0.668115,validation loss:0.668613
epoch 92/200,training loss:0.667901,validation loss:0.668630
epoch 93/200,training loss:0.668034,validation loss:0.668407
epoch 94/200,training loss:0.668158,validation loss:0.668534
epoch 95/200,training loss:0.667636,validation loss:0.668805
epoch 96/200,training loss:0.667795,validation loss:0.668265
epoch 97/200,training loss:0.667414,validation loss:0.668866
epoch 98/200,training loss:0.667549,validation loss:0.667965
epoch 99/200,training loss:0.667411,validation loss:0.668402
epoch 100/200,training loss:0.667840,validation loss:0.667708
epoch 101/200,training loss:0.667587,validation loss:0.667972
epoch 102/200,training loss:0.667108,validation loss:0.667418
epoch 103/200,training loss:0.667619,validation loss:0.668417
epoch 104/200,training loss:0.667300,validation loss:0.667766
epoch 105/200,training loss:0.667370,validation loss:0.668254
epoch 106/200,training loss:0.667251,validation loss:0.667820
epoch 107/200,training loss:0.667385,validation loss:0.667564
epoch 108/200,training loss:0.667203,validation loss:0.667566
epoch 109/200,training loss:0.667224,validation loss:0.667810
epoch 110/200,training loss:0.666871,validation loss:0.667479
epoch 111/200,training loss:0.666933,validation loss:0.667479
epoch 112/200,training loss:0.666979,validation loss:0.667539
epoch 113/200,training loss:0.667100,validation loss:0.667680
epoch 114/200,training loss:0.666960,validation loss:0.667551
epoch 115/200,training loss:0.666848,validation loss:0.667442
epoch 116/200,training loss:0.666855,validation loss:0.667320
epoch 117/200,training loss:0.666453,validation loss:0.667311
epoch 118/200,training loss:0.666727,validation loss:0.667012
epoch 119/200,training loss:0.666528,validation loss:0.667290
epoch 120/200,training loss:0.666568,validation loss:0.667194
epoch 121/200,training loss:0.666591,validation loss:0.667195
epoch 122/200,training loss:0.666266,validation loss:0.667127
epoch 123/200,training loss:0.666360,validation loss:0.667103
epoch 124/200,training loss:0.666329,validation loss:0.667291
epoch 125/200,training loss:0.666432,validation loss:0.667300
epoch 126/200,training loss:0.666340,validation loss:0.666859
epoch 127/200,training loss:0.666151,validation loss:0.666711
epoch 128/200,training loss:0.666263,validation loss:0.667279
epoch 129/200,training loss:0.666388,validation loss:0.666822
epoch 130/200,training loss:0.666391,validation loss:0.667078
epoch 131/200,training loss:0.666598,validation loss:0.667267
epoch 132/200,training loss:0.666031,validation loss:0.667439
epoch 133/200,training loss:0.666021,validation loss:0.666716
epoch 134/200,training loss:0.666158,validation loss:0.666507
epoch 135/200,training loss:0.666072,validation loss:0.666987
epoch 136/200,training loss:0.665809,validation loss:0.667260
epoch 137/200,training loss:0.666552,validation loss:0.667071
epoch 138/200,training loss:0.666027,validation loss:0.666735
epoch 139/200,training loss:0.665960,validation loss:0.666419
epoch 140/200,training loss:0.665975,validation loss:0.667039
epoch 141/200,training loss:0.665927,validation loss:0.666403
epoch 142/200,training loss:0.665971,validation loss:0.666478
epoch 143/200,training loss:0.665846,validation loss:0.666546
epoch 144/200,training loss:0.665323,validation loss:0.667146
epoch 145/200,training loss:0.666089,validation loss:0.666672
epoch 146/200,training loss:0.665658,validation loss:0.666654
epoch 147/200,training loss:0.665977,validation loss:0.666315
epoch 148/200,training loss:0.666038,validation loss:0.666547
epoch 149/200,training loss:0.665794,validation loss:0.666572
epoch 150/200,training loss:0.665699,validation loss:0.666164
epoch 151/200,training loss:0.665688,validation loss:0.666158
epoch 152/200,training loss:0.665381,validation loss:0.666351
epoch 153/200,training loss:0.665754,validation loss:0.666479
epoch 154/200,training loss:0.665454,validation loss:0.666327
epoch 155/200,training loss:0.665533,validation loss:0.666489
epoch 156/200,training loss:0.665528,validation loss:0.666627
epoch 157/200,training loss:0.665432,validation loss:0.666298
epoch 158/200,training loss:0.665390,validation loss:0.666226
epoch 159/200,training loss:0.665469,validation loss:0.666148
epoch 160/200,training loss:0.665598,validation loss:0.666439
epoch 161/200,training loss:0.665158,validation loss:0.666374
epoch 162/200,training loss:0.665582,validation loss:0.665946
epoch 163/200,training loss:0.665639,validation loss:0.666135
epoch 164/200,training loss:0.665427,validation loss:0.666241
epoch 165/200,training loss:0.665472,validation loss:0.665974
epoch 166/200,training loss:0.665384,validation loss:0.666377
epoch 167/200,training loss:0.665265,validation loss:0.666237
epoch 168/200,training loss:0.665432,validation loss:0.666350
epoch 169/200,training loss:0.665221,validation loss:0.666666
epoch 170/200,training loss:0.665708,validation loss:0.666250
epoch 171/200,training loss:0.665090,validation loss:0.666322
epoch 172/200,training loss:0.665410,validation loss:0.666291
epoch 173/200,training loss:0.665393,validation loss:0.665687
epoch 174/200,training loss:0.665037,validation loss:0.665742
epoch 175/200,training loss:0.664989,validation loss:0.666089
epoch 176/200,training loss:0.665227,validation loss:0.666035
epoch 177/200,training loss:0.665219,validation loss:0.666027
epoch 178/200,training loss:0.665160,validation loss:0.665745
epoch 179/200,training loss:0.665185,validation loss:0.666042
epoch 180/200,training loss:0.664965,validation loss:0.665938
epoch 181/200,training loss:0.665069,validation loss:0.665455
epoch 182/200,training loss:0.665083,validation loss:0.666126
epoch 183/200,training loss:0.665148,validation loss:0.665842
epoch 184/200,training loss:0.665070,validation loss:0.665728
epoch 185/200,training loss:0.665178,validation loss:0.666334
epoch 186/200,training loss:0.664939,validation loss:0.665359
epoch 187/200,training loss:0.665005,validation loss:0.665473
epoch 188/200,training loss:0.664771,validation loss:0.666118
epoch 189/200,training loss:0.665078,validation loss:0.665683
epoch 190/200,training loss:0.665180,validation loss:0.666054
epoch 191/200,training loss:0.664746,validation loss:0.666058
epoch 192/200,training loss:0.665089,validation loss:0.665565
epoch 193/200,training loss:0.664696,validation loss:0.665721
epoch 194/200,training loss:0.665127,validation loss:0.665741
epoch 195/200,training loss:0.664679,validation loss:0.665904
epoch 196/200,training loss:0.665124,validation loss:0.665751
epoch 197/200,training loss:0.664948,validation loss:0.665817
epoch 198/200,training loss:0.665026,validation loss:0.665836
epoch 199/200,training loss:0.664784,validation loss:0.666081
Finished. Saving the model to /h/172/shawnlyu/projects/machine_learning/CSC2515Dota2DraftPredictionProject/algorithms/shawn/exp_VH/fc_8.batch.pth
The best validation accuracy occurs at 0th epoch