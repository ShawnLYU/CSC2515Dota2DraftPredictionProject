{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=pd.read_csv('../data/Semenov2017PaperData_matches_dota.csv',nrows=2)\n",
    "D=D.loc[D['leavers']==0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out=sparse.csc_matrix(D['radiant_win'])\n",
    "train_heroes=D.loc[:,'r1_hero_id':]\n",
    "trainX=np.zeros((D.shape[0],2*113))\n",
    "for i in range(D.shape[0]):\n",
    "    trainX[i,train_heroes.iloc[i,0:5].values-1]=np.ones(5)\n",
    "    trainX[i,train_heroes.iloc[i,5:10].values-1+113]=np.ones(5)\n",
    "In=sparse.csr_matrix(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  1 st block of 10000 records\n",
      "Processing  51 st block of 10000 records\n",
      "Processing  101 st block of 10000 records\n",
      "Processing  151 st block of 10000 records\n",
      "Processing  201 st block of 10000 records\n",
      "Processing  251 st block of 10000 records\n",
      "Processing  301 st block of 10000 records\n",
      "Processing  351 st block of 10000 records\n",
      "Processing  401 st block of 10000 records\n",
      "Processing  451 st block of 10000 records\n",
      "Processing  501 st block of 10000 records\n"
     ]
    }
   ],
   "source": [
    "m=10000\n",
    "j=0\n",
    "for chunk in pd.read_csv('../data/Semenov2017PaperData_matches_dota.csv',chunksize=m):\n",
    "    if j%50==0:\n",
    "        print('Processing ',j+1,'st block of 10000 records')\n",
    "    j+=1\n",
    "        \n",
    "    D=chunk.loc[chunk['leavers']==0,:]\n",
    "    n=D.shape[0]\n",
    "    Out=sparse.hstack([Out,sparse.csc_matrix(D['radiant_win'])])\n",
    "    train_heroes=D.loc[:,'r1_hero_id':]\n",
    "    trainX=np.zeros((n,2*113))\n",
    "    for i in range(D.shape[0]):\n",
    "        trainX[i,train_heroes.iloc[i,0:5].values-1]=np.ones(5)\n",
    "        trainX[i,train_heroes.iloc[i,5:10].values-1+113]=np.ones(5)\n",
    "    In=sparse.vstack([In,sparse.csr_matrix(trainX)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Matrix size (4182501, 226)\n",
      "Output Matrix size (1, 4182501)\n"
     ]
    }
   ],
   "source": [
    "print('Input Matrix size', In.shape)\n",
    "print('Output Matrix size', Out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainX size (2092295, 226)\n",
      "ValidX size (1044580, 226)\n",
      "TestX size (1045626, 226)\n",
      "TrainY size (2092295, 1)\n",
      "ValidY size (1044580, 1)\n",
      "TestY size (1045626, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "tempX, TestX, tempY, TestY = train_test_split(In,Out.transpose(),test_size=0.25)\n",
    "TrainX, ValidX, TrainY, ValidY = train_test_split(tempX,tempY,test_size=0.333)\n",
    "print('TrainX size', TrainX.shape)\n",
    "print('ValidX size', ValidX.shape)\n",
    "print('TestX size', TestX.shape)\n",
    "print('TrainY size', TrainY.shape)\n",
    "print('ValidY size', ValidY.shape)\n",
    "print('TestY size', TestY.shape)\n",
    "sparse.save_npz('TrainInput_sparse_noleave.npz',TrainX)\n",
    "sparse.save_npz('ValidInput_sparse_noleave.npz',ValidX)\n",
    "sparse.save_npz('TestInput_sparse_noleave.npz',TestX)\n",
    "sparse.save_npz('TrainOutput_sparse_noleave.npz',TrainY)\n",
    "sparse.save_npz('ValidOutput_sparse_noleave.npz',ValidY)\n",
    "sparse.save_npz('TestOutput_sparse_noleave.npz',TestY)\n",
    "with open('AllSetSparseInOut_noleave.npz','wb') as handle:\n",
    "    np.savez_compressed(handle,TrainX=TrainX,ValidX=ValidX,TestX=TestX,TrainY=TrainY,ValidY=ValidY,TestY=TestY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
